{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gendered Pronoun Resolution: Version-10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rezwanh001/Kaggle-Competition-Gendered-Pronoun-Resolution/blob/master/Gendered_Pronoun_Resolution_Version_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OaHnm9HUab0U",
        "colab_type": "code",
        "outputId": "b1197e8b-1d9f-4d3d-cda2-1a3f0ee7ce23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kqeNH_3Raktz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import pprint\n",
        "# import tensorflow as tf\n",
        "\n",
        "# if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "#   print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "# else:\n",
        "#   tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "#   print ('TPU address is', tpu_address)\n",
        "\n",
        "#   with tf.Session(tpu_address) as session:\n",
        "#     devices = session.list_devices()\n",
        "    \n",
        "#   print('TPU devices:')\n",
        "#   pprint.pprint(devices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xWirk_Vga7sj",
        "colab_type": "code",
        "outputId": "c9c847d6-ab93-4dbd-a900-50432b532576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TnCcxAAmbEUV",
        "colab_type": "code",
        "outputId": "0b769a93-40ca-41c7-8efc-51562aac9725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "# to access kaggle datasets\n",
        "!pip install kaggle\n",
        "\n",
        "# Math operations\n",
        "!pip install numpy==1.15.0"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.2)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.0.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.23)\n",
            "Requirement already satisfied: numpy==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VAxLPHMpbJlJ",
        "colab_type": "code",
        "outputId": "9b9be73f-b609-4aee-bafe-b9d6fe3059af",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "# Colab's file access feature\n",
        "from google.colab import files\n",
        "\n",
        "# retrieve upload file\n",
        "uploaded = files.upload()\n",
        "\n",
        "#print results\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.jason into the folder where the API expects to to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/kaggle/kaggle.json "
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-107dd0d4-0592-42f1-a2df-4e69be62eba6\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-107dd0d4-0592-42f1-a2df-4e69be62eba6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 65 bytes\n",
            "chmod: cannot access '/root/kaggle/kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_c-nSdN6bNKM",
        "colab_type": "code",
        "outputId": "d69526d4-02d8-4436-9687-70b2ee0a1922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "# list competitions\n",
        "!kaggle competitions list\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "ref                                            deadline             category            reward  teamCount  userHasEntered  \n",
            "---------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "digit-recognizer                               2030-01-01 00:00:00  Getting Started  Knowledge       2497           False  \n",
            "titanic                                        2030-01-01 00:00:00  Getting Started  Knowledge       9924            True  \n",
            "house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started  Knowledge       4096           False  \n",
            "imagenet-object-localization-challenge         2029-12-31 07:00:00  Research         Knowledge         35           False  \n",
            "competitive-data-science-predict-future-sales  2019-12-31 23:59:00  Playground           Kudos       2394           False  \n",
            "two-sigma-financial-news                       2019-07-15 23:59:00  Featured          $100,000       2927           False  \n",
            "LANL-Earthquake-Prediction                     2019-06-03 23:59:00  Research           $50,000       1326            True  \n",
            "tmdb-box-office-prediction                     2019-05-30 23:59:00  Playground       Knowledge        272           False  \n",
            "dont-overfit-ii                                2019-05-07 23:59:00  Playground            Swag        761           False  \n",
            "gendered-pronoun-resolution                    2019-04-22 23:59:00  Research           $25,000        246            True  \n",
            "santander-customer-transaction-prediction      2019-04-10 23:59:00  Featured           $65,000       2384           False  \n",
            "womens-machine-learning-competition-2019       2019-04-09 23:59:00  Featured           $25,000         90           False  \n",
            "mens-machine-learning-competition-2019         2019-04-08 23:59:00  Featured           $25,000        157           False  \n",
            "histopathologic-cancer-detection               2019-03-30 23:59:00  Playground       Knowledge        718           False  \n",
            "petfinder-adoption-prediction                  2019-03-28 23:59:00  Featured           $25,000       1301           False  \n",
            "vsb-power-line-fault-detection                 2019-03-21 23:59:00  Featured           $25,000       1046           False  \n",
            "microsoft-malware-prediction                   2019-03-13 23:59:00  Research           $25,000       1929           False  \n",
            "humpback-whale-identification                  2019-02-28 23:59:00  Featured           $25,000       2084           False  \n",
            "elo-merchant-category-recommendation           2019-02-26 23:59:00  Featured           $50,000       4161            True  \n",
            "ga-customer-revenue-prediction                 2019-02-21 20:04:00  Featured           $45,000       1100            True  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rQwJfvLnbUp-",
        "colab_type": "code",
        "outputId": "c5c0ca44-aad0-4ee5-e9da-1d1e4c844c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "#download gendered-pronoun-resolution data\n",
        "!kaggle competitions download -c gendered-pronoun-resolution"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "sample_submission_stage_1.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_stage_1.tsv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RS-qcHXgf96P",
        "colab_type": "code",
        "outputId": "052cb2e1-e176-4a22-b600-ddcbd3cad4c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "###=============== Import necessary Libraries ==================\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import string\n",
        "import keras\n",
        "from pandas.io.json import json_normalize\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "from math import floor\n",
        "import spacy\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from plotly import tools\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "from sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import lightgbm as lgb\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, Concatenate, Add, Flatten, CuDNNLSTM\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.engine.topology import Layer\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np # linear algebra\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "pd.options.display.max_columns = 999\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# keras libraries\n",
        "from keras.models import Model, load_model,Sequential\n",
        "from keras.layers import Dense, Input, Dropout,Bidirectional, GRU, Activation, concatenate, Embedding, SpatialDropout1D\n",
        "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D ,GlobalMaxPool1D, GlobalAvgPool1D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras import layers\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/vnd.plotly.v1+html": "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>",
            "text/html": [
              "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "viX7O-jtgaVy",
        "colab_type": "code",
        "outputId": "4b5a6455-cfa1-42ad-d4d9-8ef30480a469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "##======== Load text and tokenize ====================\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(u'A few days later, Abigail complained that Elizabeth was pinching her and tearing at her bowels')\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.tag_, token.dep_)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A DET DT det\n",
            "few ADJ JJ amod\n",
            "days NOUN NNS npadvmod\n",
            "later ADV RB advmod\n",
            ", PUNCT , punct\n",
            "Abigail PROPN NNP nsubj\n",
            "complained VERB VBD ROOT\n",
            "that ADP IN mark\n",
            "Elizabeth PROPN NNP nsubj\n",
            "was VERB VBD aux\n",
            "pinching VERB VBG ccomp\n",
            "her PRON PRP dobj\n",
            "and CCONJ CC cc\n",
            "tearing VERB VBG conj\n",
            "at ADP IN prep\n",
            "her ADJ PRP$ poss\n",
            "bowels NOUN NNS pobj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "feEuY8aQg3LE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "####======================= Define necessary libraries ========================\n",
        "def word_locate(sentence, location): \n",
        "    count_words = 0\n",
        "    count_chars = 2 #2 is to count for the two spaces in the beginning\n",
        "    for word in sentence.split():\n",
        "        count_words += 1\n",
        "        if location == count_chars:\n",
        "            return word, count_words\n",
        "        count_chars += len(word)\n",
        "        count_chars += 1 #for space\n",
        "        \n",
        "def curr_prev_sentence(sentence, loc):\n",
        "    current_sentence = \"\"\n",
        "    prev_sentence = \"\"\n",
        "    detect = 0\n",
        "    count = 0\n",
        "    for char in sentence:\n",
        "        count += 1\n",
        "        current_sentence += char\n",
        "        if char == \".\" and detect == 0:\n",
        "            prev_sentence = current_sentence \n",
        "            current_sentence = \"\"\n",
        "        if char == \".\" and detect == 1:\n",
        "            return current_sentence, prev_sentence\n",
        "        if count == loc:\n",
        "            detect = 1\n",
        "\n",
        "def find_subject(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            return token.text\n",
        "    return \"none\"            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k9x3mnHahn0g",
        "colab_type": "code",
        "outputId": "12c05560-9675-4184-8889-64413853c66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "text1 = \"After a few years of almost no work -- although he was a guest star on Lou Grant and Charlie's Angels in the late 1970s, he once summed up the 1970s as 'I cried and did a lot of gardening' -- he was hired in 1979 for his best-known role, self-made millionaire Palmer Cortlandt on ABC's long-running soap opera All My Children. Initially hired for only one year, he remained on contract through 2009. For much of his first decade on the show, Palmer was a ruthless villain, totally possessive of his daughter, Nina and violently threatening his ex-wife Daisy with being attacked by dobermans when she came back from the dead.\"\n",
        "\n",
        "text2 = \"When onlookers expressed doubt, claiming that the Proctor family was well regarded in the community, the girl promptly came out of her trance and told them it was all for 'sport'. On March 29, 1692, Abigail Williams and Mercy Lewis again said they were being tormented by Elizabeth's spectre. A few days later, Abigail complained that Elizabeth was pinching her and tearing at her bowels, and said she saw Elizabeth's spectre as well as John's.\"\n",
        "\n",
        "current, prev = curr_prev_sentence(text2, 360)\n",
        "print(current)\n",
        "\n",
        "candidate = find_subject(current)\n",
        "print(candidate)\n",
        "\n",
        "word, loc = word_locate(text2, 360) \n",
        "print(word, \" \", loc)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " A few days later, Abigail complained that Elizabeth was pinching her and tearing at her bowels, and said she saw Elizabeth's spectre as well as John's.\n",
            "Abigail\n",
            "her   60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bYPmwZvbh4hv",
        "colab_type": "code",
        "outputId": "7d323a09-b4e0-4145-9121-2b7792031dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t sample_data\t\t\ttest_stage_1.tsv\n",
            "gap-coreference  sample_submission_stage_1.csv\ttest_stage_1.tsv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nzK3Yj7YiVIQ",
        "colab_type": "code",
        "outputId": "6ae0f155-1380-498e-fc5e-87cd1403a70c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip test_stage_1.tsv.zip"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test_stage_1.tsv.zip\n",
            "replace test_stage_1.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y84y7wFuicdD",
        "colab_type": "code",
        "outputId": "04e85154-cdf0-4e4d-9f6e-b9b330060aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "!git clone https://github.com/google-research-datasets/gap-coreference.git\n",
        "\n",
        "#!wget 'https://github.com/google-research-datasets/gap-coreference/blob/master/gap-development.tsv'\n",
        "\n",
        "#!files.download('https://github.com/google-research-datasets/gap-coreference/blob/master/gap-development.tsv') # then browse, select the files. It's then uploaded\n",
        "\n",
        "# uploaded is now a dict containing \"filename\" -> Content"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'gap-coreference' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OSj7ykj9kmPp",
        "colab_type": "code",
        "outputId": "1d6e133b-ca99-4244-f6a6-71375b18f2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t sample_data\t\t\ttest_stage_1.tsv\n",
            "gap-coreference  sample_submission_stage_1.csv\ttest_stage_1.tsv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RRXhMeXYlBFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### ======================== load test_stage_1\n",
        "with open('test_stage_1.tsv') as tsvfile:\n",
        "    reader = csv.DictReader(tsvfile, dialect='excel-tab')\n",
        "    testA_X = []\n",
        "    testB_X = []\n",
        "    test_auX = []\n",
        "    test_ids = []\n",
        "    train_auX = [] #we do a small hack and fill up the aux train data twice, like train hopping \n",
        "    for row in reader:\n",
        "        text = row['Text']\n",
        "        textA = text.lower()\n",
        "        test_auX.append(text.lower())#test aux is half size of train aux\n",
        "        train_auX.append(text.lower()) #since test loop is running, why not fill up aux train in meantime \n",
        "        new_textA = textA\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(textA)):\n",
        "            if char_idx == int(row['A-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"person_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"pronom_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "        testA_X.append(new_textA)\n",
        "        textB = text.lower()\n",
        "        new_textB = textB\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(textB)):\n",
        "            if char_idx == int(row['B-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"person_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"pronom_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "        testB_X.append(new_textB)\n",
        "        test_ids.append(row['ID'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_Ov5j4slsIg",
        "colab_type": "code",
        "outputId": "e6993b89-1b8a-4d13-8e3f-f6c2a45d2ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(test_ids))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hIBtvwvKFbBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "1a1a4ac5-5cb1-4834-a3c9-1cc7f01b9ee0"
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution '"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " answers_1.csv\n",
            " answers.csv\n",
            " gendered-pronoun-resolution\n",
            "'Gendered Pronoun Resolution: Version-09.ipynb'\n",
            " submission_1.csv\n",
            " submission_2.csv\n",
            " submission_3.csv\n",
            " submission_4.csv\n",
            " submission_5.csv\n",
            " submission_8.csv\n",
            " submission_9.csv\n",
            " test_ids.pckl\n",
            "'Top 3 NLP Libraries Tutorial( NLTK+spaCy+Gensim).ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WU0vexLPEWsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## save : test_ids\n",
        "import pickle\n",
        "\n",
        "f = open('/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /test_ids.pckl', 'wb')\n",
        "pickle.dump(test_ids, f)\n",
        "f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbbRjUXOGD_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "94bcbb2a-2c66-44b9-bcf3-f37b13e4d2e7"
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution '"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " answers_1.csv\n",
            " answers.csv\n",
            " gendered-pronoun-resolution\n",
            "'Gendered Pronoun Resolution: Version-09.ipynb'\n",
            " submission_1.csv\n",
            " submission_2.csv\n",
            " submission_3.csv\n",
            " submission_4.csv\n",
            " submission_5.csv\n",
            " submission_8.csv\n",
            " submission_9.csv\n",
            " test_ids.pckl\n",
            "'Top 3 NLP Libraries Tutorial( NLTK+spaCy+Gensim).ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YaGUIpRsltZo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########=============================== Load gap-development.tsv ===================\n",
        "with open('/content/gap-coreference/gap-development.tsv') as tsvfile:\n",
        "    reader = csv.DictReader(tsvfile, dialect='excel-tab')\n",
        "#     print(*reader)\n",
        "    train_X = []\n",
        "    train_y = []\n",
        "    for row in reader:\n",
        "#         print(row)\n",
        "        text = row[\"Text\"]\n",
        "        text = text.lower()\n",
        "        train_auX.append(text)\n",
        "        new_textA = text\n",
        "        labelA = 0\n",
        "        labelB = 0\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(text)):\n",
        "            if char_idx == int(row['A-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"person_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"pronom_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "        if row['A-coref'] == 'TRUE':\n",
        "            labelA = 1\n",
        "        train_X.append(new_textA)\n",
        "        train_y.append(labelA)\n",
        "        new_textB = text\n",
        "        label = 0\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(text)):\n",
        "            if char_idx == int(row['B-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"person_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"pronom_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "        if row['B-coref'] == 'TRUE':\n",
        "            labelB = 1\n",
        "        train_X.append(new_textB)\n",
        "        train_y.append(labelB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xzHyV88Wl58u",
        "colab_type": "code",
        "outputId": "b71dd1b4-978b-4ecf-8e3e-bf6d0cd8867e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(train_X))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vGjAFoiqpKM6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###============= Tokenize \n",
        "maxlen = 220\n",
        "embed_size = 500\n",
        "max_features = 7000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62w66gGmpPia",
        "colab_type": "code",
        "outputId": "172f4fbf-dfc8-4517-fd4c-798b71eb977f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer_list = list(train_X)\n",
        "tokenizer.fit_on_texts(tokenizer_list)\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "testA_X = tokenizer.texts_to_sequences(testA_X)\n",
        "testB_X = tokenizer.texts_to_sequences(testB_X)\n",
        "test_auX = tokenizer.texts_to_sequences(test_auX)\n",
        "train_auX = tokenizer.texts_to_sequences(train_auX)\n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "testA_X = pad_sequences(testA_X, maxlen=maxlen)\n",
        "testB_X = pad_sequences(testB_X, maxlen=maxlen)\n",
        "test_auX = pad_sequences(test_auX, maxlen=maxlen)\n",
        "train_auX = pad_sequences(train_auX, maxlen=maxlen)\n",
        "\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "max_features = len(word_index)\n",
        "\n",
        "print(max_features)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mKyYwJgxpfHj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatible with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "      \n",
        "      \n",
        "class AttentionWithContext(Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qZQOpj56prTL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_y = np.asarray(train_y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "142jGoYkpvny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##==========================Define CuDNNGRU model\n",
        "def get_model_1():\n",
        "  inp1 = Input(shape=(maxlen,))\n",
        "  inp2 = Input(shape=(maxlen,))\n",
        "\n",
        "  model1_out = Embedding(max_features, embed_size)(inp1)\n",
        "  model1_out = Bidirectional(CuDNNGRU(256, return_sequences=True))(model1_out)\n",
        "  model1_out = AttentionWithContext()(model1_out)\n",
        "  model1_out = Dropout(0.1)(model1_out)\n",
        "\n",
        "  model2_out = Embedding(max_features, embed_size)(inp2)\n",
        "  model2_out = Bidirectional(CuDNNGRU(256, return_sequences=True))(model2_out)\n",
        "  model2_out = AttentionWithContext()(model2_out)\n",
        "  model2_out = Dropout(0.1)(model2_out)\n",
        "\n",
        "  merged_out = keras.layers.Concatenate(axis=1)([model1_out, model2_out])\n",
        "\n",
        "  merged_out = Dense(32, activation=\"relu\")(merged_out)\n",
        "  merged_out = Dropout(0.1)(merged_out)\n",
        "  \n",
        "  merged_out = Dense(1, activation=\"sigmoid\")(merged_out)\n",
        "  model = Model(inputs=[inp1,inp2], outputs=merged_out)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e6a6eWRaBcoH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##==========================Define LSTM model\n",
        "def get_model_2():\n",
        "  inp1 = Input(shape=(maxlen,))\n",
        "  inp2 = Input(shape=(maxlen,))\n",
        "\n",
        "  model1_out = Embedding(max_features, embed_size)(inp1)\n",
        "  model1_out = Bidirectional(LSTM(256, return_sequences=True))(model1_out)\n",
        "  model1_out = AttentionWithContext()(model1_out)\n",
        "  model1_out = Dropout(0.1)(model1_out)\n",
        "\n",
        "  model2_out = Embedding(max_features, embed_size)(inp2)\n",
        "  model2_out = Bidirectional(LSTM(256, return_sequences=True))(model2_out)\n",
        "  model2_out = AttentionWithContext()(model2_out)\n",
        "  model2_out = Dropout(0.1)(model2_out)\n",
        "\n",
        "  merged_out = keras.layers.Concatenate(axis=1)([model1_out, model2_out])\n",
        "\n",
        "  merged_out = Dense(32, activation=\"relu\")(merged_out)\n",
        "  merged_out = Dropout(0.1)(merged_out)\n",
        "  \n",
        "  merged_out = Dense(1, activation=\"sigmoid\")(merged_out)\n",
        "  model = Model(inputs=[inp1,inp2], outputs=merged_out)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ifhlKUYBtmhB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#####==========================Define 3rd model: GRU model\n",
        "def get_model_3():\n",
        "    inp1 = Input(shape=(maxlen,))\n",
        "    inp2 = Input(shape=(maxlen,))\n",
        "\n",
        "    model1_out = Embedding(max_features, embed_size)(inp1)\n",
        "    model1_out = Bidirectional(GRU(256, return_sequences=True))(model1_out)\n",
        "    model1_out = AttentionWithContext()(model1_out)\n",
        "    model1_out = Dropout(0.1)(model1_out)\n",
        "\n",
        "    model2_out = Embedding(max_features, embed_size)(inp2)\n",
        "    model2_out = Bidirectional(GRU(256, return_sequences=True))(model2_out)\n",
        "    model2_out = AttentionWithContext()(model2_out)\n",
        "    model2_out = Dropout(0.1)(model2_out)\n",
        "\n",
        "    merged_out = keras.layers.Concatenate(axis=1)([model1_out, model2_out])\n",
        "\n",
        "    merged_out = Dense(32, activation=\"relu\")(merged_out)\n",
        "    merged_out = Dropout(0.1)(merged_out)\n",
        "\n",
        "    merged_out = Dense(1, activation=\"sigmoid\")(merged_out)\n",
        "    model = Model(inputs=[inp1,inp2], outputs=merged_out)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xfz7MVMytVwE",
        "colab_type": "code",
        "outputId": "16c4e2b5-926e-465c-cc8b-fb99f58b665c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "cell_type": "code",
      "source": [
        "########===========================Define 1stmodel: CuDNNGRU ================\n",
        "model = get_model_1()\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 220, 500)     11121500    input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 220, 500)     11121500    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 220, 512)     1164288     embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 220, 512)     1164288     embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_3 (Atten (None, 512)          263168      bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_4 (Atten (None, 512)          263168      bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 512)          0           attention_with_context_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 512)          0           attention_with_context_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1024)         0           dropout_4[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           32800       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            33          dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 25,130,745\n",
            "Trainable params: 25,130,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3vlc3awwp5vJ",
        "colab_type": "code",
        "outputId": "05b98362-aa58-4c2a-ef39-14513cd0b2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1153
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit([train_X, train_auX], train_y, batch_size=512, epochs=30, validation_data=([train_X,train_auX], train_y))\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4000 samples, validate on 4000 samples\n",
            "Epoch 1/30\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.6924 - acc: 0.5333 - val_loss: 0.6902 - val_acc: 0.5503\n",
            "Epoch 2/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.6888 - acc: 0.5505 - val_loss: 0.6884 - val_acc: 0.5503\n",
            "Epoch 3/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6858 - val_acc: 0.5503\n",
            "Epoch 4/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 0.6850 - acc: 0.5503 - val_loss: 0.6789 - val_acc: 0.5503\n",
            "Epoch 5/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 0.6706 - acc: 0.5625 - val_loss: 0.6305 - val_acc: 0.6395\n",
            "Epoch 6/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 0.6085 - acc: 0.6770 - val_loss: 0.5513 - val_acc: 0.7117\n",
            "Epoch 7/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 0.5490 - acc: 0.7180 - val_loss: 0.4955 - val_acc: 0.7632\n",
            "Epoch 8/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 0.4734 - acc: 0.7647 - val_loss: 0.3554 - val_acc: 0.8600\n",
            "Epoch 9/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 0.3225 - acc: 0.8663 - val_loss: 0.1947 - val_acc: 0.9295\n",
            "Epoch 10/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1584 - acc: 0.9423 - val_loss: 0.0737 - val_acc: 0.9770\n",
            "Epoch 11/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 0.0652 - acc: 0.9810 - val_loss: 0.0311 - val_acc: 0.9932\n",
            "Epoch 12/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 0.0382 - acc: 0.9915 - val_loss: 0.0124 - val_acc: 0.9980\n",
            "Epoch 13/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 0.0192 - acc: 0.9963 - val_loss: 0.0065 - val_acc: 0.9992\n",
            "Epoch 14/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0037 - val_acc: 0.9998\n",
            "Epoch 15/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0046 - acc: 0.9992 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 16/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0024 - acc: 0.9997 - val_loss: 6.9762e-04 - val_acc: 1.0000\n",
            "Epoch 17/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 4.1949e-04 - val_acc: 1.0000\n",
            "Epoch 18/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 5.7588e-04 - acc: 1.0000 - val_loss: 6.4259e-04 - val_acc: 0.9998\n",
            "Epoch 19/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 9.0492e-04 - acc: 0.9997 - val_loss: 7.4504e-04 - val_acc: 0.9998\n",
            "Epoch 20/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 8.7366e-04 - acc: 0.9997 - val_loss: 2.2605e-04 - val_acc: 1.0000\n",
            "Epoch 21/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 4.0450e-04 - acc: 1.0000 - val_loss: 1.8810e-04 - val_acc: 1.0000\n",
            "Epoch 22/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 2.8973e-04 - acc: 1.0000 - val_loss: 1.6924e-04 - val_acc: 1.0000\n",
            "Epoch 23/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 2.6989e-04 - acc: 1.0000 - val_loss: 1.2371e-04 - val_acc: 1.0000\n",
            "Epoch 24/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 2.5724e-04 - acc: 1.0000 - val_loss: 9.8601e-05 - val_acc: 1.0000\n",
            "Epoch 25/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 1.8709e-04 - acc: 1.0000 - val_loss: 9.9635e-05 - val_acc: 1.0000\n",
            "Epoch 26/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 1.8212e-04 - acc: 1.0000 - val_loss: 7.7917e-05 - val_acc: 1.0000\n",
            "Epoch 27/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 1.4824e-04 - acc: 1.0000 - val_loss: 6.2616e-05 - val_acc: 1.0000\n",
            "Epoch 28/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 1.3635e-04 - acc: 1.0000 - val_loss: 5.5589e-05 - val_acc: 1.0000\n",
            "Epoch 29/30\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 1.1172e-04 - acc: 1.0000 - val_loss: 5.0203e-05 - val_acc: 1.0000\n",
            "Epoch 30/30\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 1.2772e-04 - acc: 1.0000 - val_loss: 4.6067e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f60fe3dde80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "MjZt9hhYp_h7",
        "colab_type": "code",
        "outputId": "4111688c-cfc3-4dc8-ec25-63cfec4e5d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "pred_valA_y_1 = model.predict([testA_X,test_auX], batch_size=512, verbose=1)\n",
        "pred_valB_y_1 = model.predict([testB_X,test_auX], batch_size=512, verbose=1)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 2s 1ms/step\n",
            "2000/2000 [==============================] - 2s 877us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YbbcFfK4H-Os",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## save : pred_valA_y_1, pred_valB_y_1\n",
        "import pickle\n",
        "\n",
        "f = open('/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /pred_valA_y_1.pckl', 'wb')\n",
        "pickle.dump(pred_valA_y_1, f)\n",
        "f.close()\n",
        "\n",
        "\n",
        "f = open('/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /pred_valB_y_1.pckl', 'wb')\n",
        "pickle.dump(pred_valB_y_1, f)\n",
        "f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZXHWKjvxNzV",
        "colab_type": "code",
        "outputId": "ca45c99a-e0d6-4568-8272-6e3c03e0e6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution '\n",
        "# print(len(pred_valB_y_1), \" \", len(pred_valA_y_1))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " answers_1.csv\n",
            " answers.csv\n",
            " gendered-pronoun-resolution\n",
            "'Gendered Pronoun Resolution: Version-09.ipynb'\n",
            " pred_valA_y_1.pckl\n",
            " pred_valB_y_1.pckl\n",
            " submission_1.csv\n",
            " submission_2.csv\n",
            " submission_3.csv\n",
            " submission_4.csv\n",
            " submission_5.csv\n",
            " submission_8.csv\n",
            " submission_9.csv\n",
            " test_ids.pckl\n",
            "'Top 3 NLP Libraries Tutorial( NLTK+spaCy+Gensim).ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I4-i7Xsac6qI",
        "colab_type": "code",
        "outputId": "65d40216-6534-4c3a-80bc-72d786bae5bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "cell_type": "code",
      "source": [
        "####============= Define 2nd Model: LSTM =======================\n",
        "model = get_model_2()\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 220, 500)     11121500    input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 220, 500)     11121500    input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 220, 512)     1550336     embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 220, 512)     1550336     embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_5 (Atten (None, 512)          263168      bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_6 (Atten (None, 512)          263168      bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 512)          0           attention_with_context_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 512)          0           attention_with_context_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 1024)         0           dropout_7[0][0]                  \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 32)           32800       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32)           0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            33          dropout_9[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 25,902,841\n",
            "Trainable params: 25,902,841\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qnQOf4BCdEus",
        "colab_type": "code",
        "outputId": "119dbffa-128a-4d8e-fa71-678aeb8939e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1153
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit([train_X, train_auX], train_y, batch_size=512, epochs=30, validation_data=([train_X,train_auX], train_y))\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4000 samples, validate on 4000 samples\n",
            "Epoch 1/30\n",
            "4000/4000 [==============================] - 43s 11ms/step - loss: 0.6893 - acc: 0.5393 - val_loss: 0.6890 - val_acc: 0.5503\n",
            "Epoch 2/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.6882 - acc: 0.5503 - val_loss: 0.6830 - val_acc: 0.5503\n",
            "Epoch 3/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.6766 - acc: 0.5590 - val_loss: 0.6616 - val_acc: 0.6070\n",
            "Epoch 4/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.6527 - acc: 0.6418 - val_loss: 0.6139 - val_acc: 0.6735\n",
            "Epoch 5/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.5948 - acc: 0.7060 - val_loss: 0.5173 - val_acc: 0.7352\n",
            "Epoch 6/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.5337 - acc: 0.7147 - val_loss: 0.4796 - val_acc: 0.7482\n",
            "Epoch 7/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.4918 - acc: 0.7212 - val_loss: 0.4537 - val_acc: 0.7498\n",
            "Epoch 8/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.4547 - acc: 0.7290 - val_loss: 0.4312 - val_acc: 0.7542\n",
            "Epoch 9/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.4356 - acc: 0.7357 - val_loss: 0.3940 - val_acc: 0.7648\n",
            "Epoch 10/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.4089 - acc: 0.7397 - val_loss: 0.3750 - val_acc: 0.7845\n",
            "Epoch 11/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.3957 - acc: 0.7680 - val_loss: 0.3370 - val_acc: 0.8310\n",
            "Epoch 12/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.3512 - acc: 0.8130 - val_loss: 0.2948 - val_acc: 0.8818\n",
            "Epoch 13/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.3004 - acc: 0.8662 - val_loss: 0.2468 - val_acc: 0.8970\n",
            "Epoch 14/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.2417 - acc: 0.8985 - val_loss: 0.1977 - val_acc: 0.9212\n",
            "Epoch 15/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.2063 - acc: 0.9163 - val_loss: 0.1433 - val_acc: 0.9445\n",
            "Epoch 16/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.1479 - acc: 0.9460 - val_loss: 0.1102 - val_acc: 0.9593\n",
            "Epoch 17/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.1187 - acc: 0.9543 - val_loss: 0.0968 - val_acc: 0.9640\n",
            "Epoch 18/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.1048 - acc: 0.9620 - val_loss: 0.0680 - val_acc: 0.9765\n",
            "Epoch 19/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0819 - acc: 0.9740 - val_loss: 0.0781 - val_acc: 0.9713\n",
            "Epoch 20/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.0830 - acc: 0.9702 - val_loss: 0.0500 - val_acc: 0.9867\n",
            "Epoch 21/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0468 - acc: 0.9858 - val_loss: 0.0250 - val_acc: 0.9930\n",
            "Epoch 22/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.0294 - acc: 0.9915 - val_loss: 0.0159 - val_acc: 0.9977\n",
            "Epoch 23/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.0216 - acc: 0.9958 - val_loss: 0.0118 - val_acc: 0.9990\n",
            "Epoch 24/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.0140 - acc: 0.9977 - val_loss: 0.0084 - val_acc: 0.9992\n",
            "Epoch 25/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0128 - acc: 0.9982 - val_loss: 0.0090 - val_acc: 0.9992\n",
            "Epoch 26/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0120 - acc: 0.9980 - val_loss: 0.0165 - val_acc: 0.9972\n",
            "Epoch 27/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0134 - acc: 0.9967 - val_loss: 0.0156 - val_acc: 0.9962\n",
            "Epoch 28/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.0121 - acc: 0.9977 - val_loss: 0.0101 - val_acc: 0.9988\n",
            "Epoch 29/30\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.0248 - acc: 0.9933 - val_loss: 0.0280 - val_acc: 0.9945\n",
            "Epoch 30/30\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0417 - acc: 0.9900 - val_loss: 0.0305 - val_acc: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f60f6efc780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "uARriHAQdEoX",
        "colab_type": "code",
        "outputId": "46fbd02e-c123-4c61-977b-c25f4ebaf2cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "pred_valA_y_2 = model.predict([testA_X,test_auX], batch_size=512, verbose=1)\n",
        "pred_valB_y_2 = model.predict([testB_X,test_auX], batch_size=512, verbose=1)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 5s 3ms/step\n",
            "2000/2000 [==============================] - 5s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lytY0FlmIxE-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## save : pred_valA_y_2, pred_valB_y_2\n",
        "import pickle\n",
        "\n",
        "f = open('/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /pred_valA_y_2.pckl', 'wb')\n",
        "pickle.dump(pred_valA_y_2, f)\n",
        "f.close()\n",
        "\n",
        "\n",
        "f = open('/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /pred_valB_y_2.pckl', 'wb')\n",
        "pickle.dump(pred_valB_y_2, f)\n",
        "f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3yMdb_87JQ7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "8b594e38-3928-40e9-d416-ef2038c25302"
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution '\n",
        "# print(len(pred_valB_y_2), \" \", len(pred_valA_y_2))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " answers_1.csv\n",
            " answers.csv\n",
            " gendered-pronoun-resolution\n",
            "'Gendered Pronoun Resolution: Version-10.ipynb'\n",
            " pred_valA_y_1.pckl\n",
            " pred_valA_y_2.pckl\n",
            " pred_valB_y_1.pckl\n",
            " pred_valB_y_2.pckl\n",
            " submission_1.csv\n",
            " submission_2.csv\n",
            " submission_3.csv\n",
            " submission_4.csv\n",
            " submission_5.csv\n",
            " submission_8.csv\n",
            " submission_9.csv\n",
            " test_ids.pckl\n",
            "'Top 3 NLP Libraries Tutorial( NLTK+spaCy+Gensim).ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kA3HRu1MJRK6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "82fb7d80-9e2b-485d-a7ad-81fa9316dc94"
      },
      "cell_type": "code",
      "source": [
        "####============= Define 3rd Model: GRU =======================\n",
        "model = get_model_3()\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        (None, 220, 500)     11121500    input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, 220, 500)     11121500    input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_10 (Bidirectional (None, 220, 512)     1162752     embedding_10[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_11 (Bidirectional (None, 220, 512)     1162752     embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_8 (Atten (None, 512)          263168      bidirectional_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_9 (Atten (None, 512)          263168      bidirectional_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 512)          0           attention_with_context_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 512)          0           attention_with_context_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 1024)         0           dropout_10[0][0]                 \n",
            "                                                                 dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 32)           32800       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32)           0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1)            33          dropout_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 25,127,673\n",
            "Trainable params: 25,127,673\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IEwEfowQzgEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0bd2e3ca-3c7d-4fe4-8c44-9f814dedb517"
      },
      "cell_type": "code",
      "source": [
        "print(train_X.shape)\n",
        "print(train_auX.shape)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 220)\n",
            "(4000, 220)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eK-KZKC1z2CO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # k = []\n",
        "# k = np.array([train_X,train_auX])\n",
        "\n",
        "# print(k.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bjHLs6va0cpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "e07d98b4-ce4d-492c-b845-94e7b7559b8e"
      },
      "cell_type": "code",
      "source": [
        "train_X"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   11,  144, 2309],\n",
              "       [   0,    0,    0, ...,   11,  144, 2309],\n",
              "       [   0,    0,    0, ..., 4714,    3,    2],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    1,  280,  168],\n",
              "       [   0,    0,    0, ...,    6,   11,  339],\n",
              "       [   0,    0,    0, ...,    6,   11,  339]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "J5M0MoEN0mD5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "8625bf04-310a-4717-ab9b-d289a3dab30e"
      },
      "cell_type": "code",
      "source": [
        "train_auX"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   11,  144, 2309],\n",
              "       [   0,    0,    0, ..., 4714,    3,    2],\n",
              "       [   0,    0,    0, ..., 1100,    4, 1268],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,  375,  376, 4105],\n",
              "       [   0,    0,    0, ...,    1,  280,  168],\n",
              "       [   0,    0,    0, ...,    6,   11,  339]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "metadata": {
        "id": "Rqo51Git0jwm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FnCCYOBSySKq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1153
        },
        "outputId": "3b858da1-5fa8-4e26-bff9-4fbae502e913"
      },
      "cell_type": "code",
      "source": [
        "model.fit([train_X, train_auX], train_y, batch_size=512, epochs=30, validation_data=([train_X,train_auX], train_y))\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4000 samples, validate on 4000 samples\n",
            "Epoch 1/30\n",
            "4000/4000 [==============================] - 34s 8ms/step - loss: 0.6913 - acc: 0.5505 - val_loss: 0.6888 - val_acc: 0.5503\n",
            "Epoch 2/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6883 - acc: 0.5503 - val_loss: 0.6857 - val_acc: 0.5503\n",
            "Epoch 3/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6846 - acc: 0.5502 - val_loss: 0.6744 - val_acc: 0.5503\n",
            "Epoch 4/30\n",
            "4000/4000 [==============================] - 30s 7ms/step - loss: 0.6574 - acc: 0.5870 - val_loss: 0.6490 - val_acc: 0.6182\n",
            "Epoch 5/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6217 - acc: 0.6615 - val_loss: 0.5736 - val_acc: 0.6957\n",
            "Epoch 6/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.5526 - acc: 0.7065 - val_loss: 0.5024 - val_acc: 0.7422\n",
            "Epoch 7/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.5185 - acc: 0.7237 - val_loss: 0.4350 - val_acc: 0.7650\n",
            "Epoch 8/30\n",
            "4000/4000 [==============================] - 30s 7ms/step - loss: 0.4423 - acc: 0.7532 - val_loss: 0.3572 - val_acc: 0.8457\n",
            "Epoch 9/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.3330 - acc: 0.8483 - val_loss: 0.2078 - val_acc: 0.9175\n",
            "Epoch 10/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.1990 - acc: 0.9170 - val_loss: 0.1130 - val_acc: 0.9635\n",
            "Epoch 11/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.1126 - acc: 0.9607 - val_loss: 0.0713 - val_acc: 0.9778\n",
            "Epoch 12/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.0706 - acc: 0.9758 - val_loss: 0.0464 - val_acc: 0.9830\n",
            "Epoch 13/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.0425 - acc: 0.9852 - val_loss: 0.0181 - val_acc: 0.9965\n",
            "Epoch 14/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.0186 - acc: 0.9953 - val_loss: 0.0059 - val_acc: 0.9990\n",
            "Epoch 15/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.0043 - val_acc: 0.9992\n",
            "Epoch 16/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 17/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.0037 - acc: 0.9992 - val_loss: 0.0037 - val_acc: 0.9990\n",
            "Epoch 18/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0051 - val_acc: 0.9987\n",
            "Epoch 19/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0034 - val_acc: 0.9995\n",
            "Epoch 20/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.3418 - acc: 0.7852 - val_loss: 0.6927 - val_acc: 0.5503\n",
            "Epoch 21/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6926 - acc: 0.5502 - val_loss: 0.6924 - val_acc: 0.5503\n",
            "Epoch 22/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6923 - acc: 0.5502 - val_loss: 0.6920 - val_acc: 0.5503\n",
            "Epoch 23/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6918 - acc: 0.5503 - val_loss: 0.6916 - val_acc: 0.5503\n",
            "Epoch 24/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6914 - acc: 0.5502 - val_loss: 0.6912 - val_acc: 0.5503\n",
            "Epoch 25/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6911 - acc: 0.5503 - val_loss: 0.6909 - val_acc: 0.5503\n",
            "Epoch 26/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6908 - acc: 0.5503 - val_loss: 0.6906 - val_acc: 0.5503\n",
            "Epoch 27/30\n",
            "4000/4000 [==============================] - 30s 7ms/step - loss: 0.6905 - acc: 0.5503 - val_loss: 0.6903 - val_acc: 0.5503\n",
            "Epoch 28/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6902 - acc: 0.5503 - val_loss: 0.6901 - val_acc: 0.5503\n",
            "Epoch 29/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6900 - acc: 0.5502 - val_loss: 0.6899 - val_acc: 0.5503\n",
            "Epoch 30/30\n",
            "4000/4000 [==============================] - 29s 7ms/step - loss: 0.6898 - acc: 0.5503 - val_loss: 0.6897 - val_acc: 0.5503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f60f2bdb470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "d4c85I9221zp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bkkz4GO_2gjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a60b783d-7313-4a98-8c4c-ebacac01bf7a"
      },
      "cell_type": "code",
      "source": [
        "pred_valA_y_3 = model.predict([testA_X,test_auX], batch_size=512, verbose=1)\n",
        "pred_valB_y_3 = model.predict([testB_X,test_auX], batch_size=512, verbose=1)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 5s 2ms/step\n",
            "2000/2000 [==============================] - 4s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f7GysLZE21Qi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## save : pred_valA_y_3, pred_valB_y_3\n",
        "import pickle\n",
        "\n",
        "f = open('/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /pred_valA_y_3.pckl', 'wb')\n",
        "pickle.dump(pred_valA_y_3, f)\n",
        "f.close()\n",
        "\n",
        "\n",
        "f = open('/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /pred_valB_y_3.pckl', 'wb')\n",
        "pickle.dump(pred_valB_y_3, f)\n",
        "f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNGuHbM-2ggL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uhpjPeC2dU9z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_vA_y = (pred_valA_y_1 + pred_valA_y_2 + pred_valA_y_3)/3.0\n",
        "pred_vB_y = (pred_valB_y_1 + pred_valB_y_2 + pred_valB_y_3)/3.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vFo5Tt1B3LKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "cda0a71a-9d7c-454d-d264-b5ba3879bb47"
      },
      "cell_type": "code",
      "source": [
        "print(pred_vA_y)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.82597953]\n",
            " [0.20224415]\n",
            " [0.6430016 ]\n",
            " ...\n",
            " [0.48917603]\n",
            " [0.8259473 ]\n",
            " [0.17432868]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bfK2tfuY3LwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "84fe51b3-588a-428e-fa54-93fcdebfa8c8"
      },
      "cell_type": "code",
      "source": [
        "print(pred_vB_y)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.82599896]\n",
            " [0.15988697]\n",
            " [0.8253613 ]\n",
            " ...\n",
            " [0.16692625]\n",
            " [0.16865252]\n",
            " [0.8259342 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i0dfiT8nxRO5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df = pd.DataFrame({\"ID\":test_ids})\n",
        "out_df['A'] = [max(float(val),0.33) for val in list(pred_vA_y)]\n",
        "out_df['B'] = [max(float(val),0.33) for val in list(pred_vB_y)]\n",
        "out_df['NEITHER'] = [max((1-float(val)),0.33) for val in list(pred_vA_y)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gVJuG_wZT7JT",
        "colab_type": "code",
        "outputId": "c5d088d2-f2bb-487e-9670-cd8aa75235b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "out_df.head(10)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>NEITHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>0.825980</td>\n",
              "      <td>0.825999</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.797756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>0.643002</td>\n",
              "      <td>0.825361</td>\n",
              "      <td>0.356998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.461058</td>\n",
              "      <td>0.840662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.840662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>development-6</td>\n",
              "      <td>0.826004</td>\n",
              "      <td>0.820161</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>development-7</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.398909</td>\n",
              "      <td>0.840549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>development-8</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.822804</td>\n",
              "      <td>0.840562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development-9</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.822592</td>\n",
              "      <td>0.764555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>development-10</td>\n",
              "      <td>0.825633</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID         A         B   NEITHER\n",
              "0   development-1  0.825980  0.825999  0.330000\n",
              "1   development-2  0.330000  0.330000  0.797756\n",
              "2   development-3  0.643002  0.825361  0.356998\n",
              "3   development-4  0.330000  0.461058  0.840662\n",
              "4   development-5  0.330000  0.330000  0.840662\n",
              "5   development-6  0.826004  0.820161  0.330000\n",
              "6   development-7  0.330000  0.398909  0.840549\n",
              "7   development-8  0.330000  0.822804  0.840562\n",
              "8   development-9  0.330000  0.822592  0.764555\n",
              "9  development-10  0.825633  0.330000  0.330000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "metadata": {
        "id": "-bwRBhWkxZ-i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df.to_csv(\"tmp_submission_10.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Xj6CAC-ffP7",
        "colab_type": "code",
        "outputId": "670e89b8-0c65-4b7f-f569-4b29325ddff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t sample_submission_stage_1.csv\ttmp_submission_10.csv\n",
            "gap-coreference  test_stage_1.tsv\n",
            "sample_data\t test_stage_1.tsv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DruSyLnUxov-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df.to_csv(\"/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /tmp_submission_10.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uYrFmuMbxenQ",
        "colab_type": "code",
        "outputId": "392bd900-1bc0-46d1-885f-f7f0b4dc1fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution '"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " answers_1.csv\n",
            " answers.csv\n",
            " gendered-pronoun-resolution\n",
            "'Gendered Pronoun Resolution: Version-10.ipynb'\n",
            " pred_valA_y_1.pckl\n",
            " pred_valA_y_2.pckl\n",
            " pred_valA_y_3.pckl\n",
            " pred_valB_y_1.pckl\n",
            " pred_valB_y_2.pckl\n",
            " pred_valB_y_3.pckl\n",
            " submission_1.csv\n",
            " submission_2.csv\n",
            " submission_3.csv\n",
            " submission_4.csv\n",
            " submission_5.csv\n",
            " submission_8.csv\n",
            " submission_9.csv\n",
            " test_ids.pckl\n",
            " tmp_submission_10.csv\n",
            "'Top 3 NLP Libraries Tutorial( NLTK+spaCy+Gensim).ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Gr5OpOHg9TW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "answers = pd.read_csv('/content/tmp_submission_10.csv', dtype={'A-coref': int, 'B-coref': int})\n",
        "answers.rename(columns={'A-coref': 'A', 'B-coref': 'B'}, inplace=True)\n",
        "answers['NEITHER'] = abs(answers.eval('1 - A - B'))\n",
        "answers[['ID', 'A', 'B', 'NEITHER']].to_csv(\"submission_10.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "isE51rP7dXrB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answers[['ID', 'A', 'B', 'NEITHER']].to_csv(\"/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /submission_10.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jCzt7VFVpFKo",
        "colab_type": "code",
        "outputId": "d1ded85f-6338-4806-b866-d744eab1cd7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t sample_submission_stage_1.csv\ttest_stage_1.tsv.zip\n",
            "gap-coreference  submission_10.csv\t\ttmp_submission_10.csv\n",
            "sample_data\t test_stage_1.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eytJsrc1otwg",
        "colab_type": "code",
        "outputId": "9f2b8373-59f0-4f5d-ec7c-348346222c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "answers.head(10)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>NEITHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>0.825980</td>\n",
              "      <td>0.825999</td>\n",
              "      <td>0.651978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>0.643002</td>\n",
              "      <td>0.825361</td>\n",
              "      <td>0.468363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.461058</td>\n",
              "      <td>0.208942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>development-6</td>\n",
              "      <td>0.826004</td>\n",
              "      <td>0.820161</td>\n",
              "      <td>0.646165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>development-7</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.398909</td>\n",
              "      <td>0.271091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>development-8</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.822804</td>\n",
              "      <td>0.152804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development-9</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.822592</td>\n",
              "      <td>0.152592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>development-10</td>\n",
              "      <td>0.825633</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.155633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID         A         B   NEITHER\n",
              "0   development-1  0.825980  0.825999  0.651978\n",
              "1   development-2  0.330000  0.330000  0.340000\n",
              "2   development-3  0.643002  0.825361  0.468363\n",
              "3   development-4  0.330000  0.461058  0.208942\n",
              "4   development-5  0.330000  0.330000  0.340000\n",
              "5   development-6  0.826004  0.820161  0.646165\n",
              "6   development-7  0.330000  0.398909  0.271091\n",
              "7   development-8  0.330000  0.822804  0.152804\n",
              "8   development-9  0.330000  0.822592  0.152592\n",
              "9  development-10  0.825633  0.330000  0.155633"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "metadata": {
        "id": "uuEZiS8Ax62F",
        "colab_type": "code",
        "outputId": "0a1f89b1-c51e-4210-9e9e-14cbb5f5ba2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "# !kaggle competitions submit -c gendered-pronoun-resolution -f tmp_submission_10.csv -m \"tmp_V-10\"\n",
        "\n",
        "!kaggle competitions submit -c gendered-pronoun-resolution -f submission_10.csv -m \"V-10\""
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "100% 111k/111k [00:01<00:00, 60.8kB/s]\n",
            "Successfully submitted to Gendered Pronoun Resolution"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "77C2wmuuyI-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}