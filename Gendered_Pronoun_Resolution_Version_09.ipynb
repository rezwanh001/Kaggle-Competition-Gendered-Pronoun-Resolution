{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gendered Pronoun Resolution: Version-09.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rezwanh001/Kaggle-Competition-Gendered-Pronoun-Resolution/blob/master/Gendered_Pronoun_Resolution_Version_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OaHnm9HUab0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "311369c8-3b23-44f7-8292-b6dd0eb36aa6"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kqeNH_3Raktz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import pprint\n",
        "# import tensorflow as tf\n",
        "\n",
        "# if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "#   print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "# else:\n",
        "#   tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "#   print ('TPU address is', tpu_address)\n",
        "\n",
        "#   with tf.Session(tpu_address) as session:\n",
        "#     devices = session.list_devices()\n",
        "    \n",
        "#   print('TPU devices:')\n",
        "#   pprint.pprint(devices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xWirk_Vga7sj",
        "colab_type": "code",
        "outputId": "bb031787-8812-4c7c-cf91-47173b897a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TnCcxAAmbEUV",
        "colab_type": "code",
        "outputId": "e0752f89-5c52-4cb9-8ef3-e4d0c6481524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "cell_type": "code",
      "source": [
        "# to access kaggle datasets\n",
        "!pip install kaggle\n",
        "\n",
        "# Math operations\n",
        "!pip install numpy==1.15.0\n",
        "\n",
        "#\n",
        "!pip install https://github.com/fchollet/keras/archive/cudnn.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.2)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.0.1)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.23)\n",
            "Collecting numpy==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/29/f4c845648ed23264e986cdc5fbab5f8eace1be5e62144ef69ccc7189461d/numpy-1.15.0-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 3.3MB/s \n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mthinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed numpy-1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/fchollet/keras/archive/cudnn.zip\n",
            "\u001b[31m  HTTP error 404 while getting https://github.com/fchollet/keras/archive/cudnn.zip\u001b[0m\n",
            "\u001b[31m  Could not install requirement https://github.com/fchollet/keras/archive/cudnn.zip because of error 404 Client Error: Not Found for url: https://codeload.github.com/keras-team/keras/zip/cudnn\u001b[0m\n",
            "\u001b[31mCould not install requirement https://github.com/fchollet/keras/archive/cudnn.zip because of HTTP error 404 Client Error: Not Found for url: https://codeload.github.com/keras-team/keras/zip/cudnn for URL https://github.com/fchollet/keras/archive/cudnn.zip\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VAxLPHMpbJlJ",
        "colab_type": "code",
        "outputId": "f7f72397-a763-4e57-bbc4-458b91bb75f4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "# Colab's file access feature\n",
        "from google.colab import files\n",
        "\n",
        "# retrieve upload file\n",
        "uploaded = files.upload()\n",
        "\n",
        "#print results\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.jason into the folder where the API expects to to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/kaggle/kaggle.json "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5a15af75-99cf-4fc3-9fbe-f6c133251b9c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5a15af75-99cf-4fc3-9fbe-f6c133251b9c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 65 bytes\n",
            "chmod: cannot access '/root/kaggle/kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_c-nSdN6bNKM",
        "colab_type": "code",
        "outputId": "07e81bdd-1af3-4173-b3b6-5234d1640059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "# list competitions\n",
        "!kaggle competitions list\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "ref                                            deadline             category            reward  teamCount  userHasEntered  \n",
            "---------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "digit-recognizer                               2030-01-01 00:00:00  Getting Started  Knowledge       2497           False  \n",
            "titanic                                        2030-01-01 00:00:00  Getting Started  Knowledge       9932            True  \n",
            "house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started  Knowledge       4098           False  \n",
            "imagenet-object-localization-challenge         2029-12-31 07:00:00  Research         Knowledge         35           False  \n",
            "competitive-data-science-predict-future-sales  2019-12-31 23:59:00  Playground           Kudos       2392           False  \n",
            "two-sigma-financial-news                       2019-07-15 23:59:00  Featured          $100,000       2927           False  \n",
            "LANL-Earthquake-Prediction                     2019-06-03 23:59:00  Research           $50,000       1307            True  \n",
            "tmdb-box-office-prediction                     2019-05-30 23:59:00  Playground       Knowledge        263           False  \n",
            "dont-overfit-ii                                2019-05-07 23:59:00  Playground            Swag        739           False  \n",
            "gendered-pronoun-resolution                    2019-04-22 23:59:00  Research           $25,000        243            True  \n",
            "santander-customer-transaction-prediction      2019-04-10 23:59:00  Featured           $65,000       2223           False  \n",
            "womens-machine-learning-competition-2019       2019-04-09 23:59:00  Featured           $25,000         90           False  \n",
            "mens-machine-learning-competition-2019         2019-04-08 23:59:00  Featured           $25,000        146           False  \n",
            "histopathologic-cancer-detection               2019-03-30 23:59:00  Playground       Knowledge        712           False  \n",
            "petfinder-adoption-prediction                  2019-03-28 23:59:00  Featured           $25,000       1291           False  \n",
            "vsb-power-line-fault-detection                 2019-03-21 23:59:00  Featured           $25,000       1038           False  \n",
            "microsoft-malware-prediction                   2019-03-13 23:59:00  Research           $25,000       1905           False  \n",
            "humpback-whale-identification                  2019-02-28 23:59:00  Featured           $25,000       2069           False  \n",
            "elo-merchant-category-recommendation           2019-02-26 23:59:00  Featured           $50,000       4141            True  \n",
            "ga-customer-revenue-prediction                 2019-02-21 20:04:00  Featured           $45,000       1100            True  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rQwJfvLnbUp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "5c46016c-7942-4415-a012-65228314b8a2"
      },
      "cell_type": "code",
      "source": [
        "#download gendered-pronoun-resolution data\n",
        "!kaggle competitions download -c gendered-pronoun-resolution"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading sample_submission_stage_1.csv to /content\n",
            "\r  0% 0.00/79.0k [00:00<?, ?B/s]\n",
            "100% 79.0k/79.0k [00:00<00:00, 70.3MB/s]\n",
            "Downloading test_stage_1.tsv.zip to /content\n",
            "  0% 0.00/425k [00:00<?, ?B/s]\n",
            "100% 425k/425k [00:00<00:00, 58.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RS-qcHXgf96P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74c8473b-2607-4c18-ef2a-201df7db88ef"
      },
      "cell_type": "code",
      "source": [
        "###=============== Import necessary Libraries ==================\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import string\n",
        "import keras\n",
        "from pandas.io.json import json_normalize\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "from math import floor\n",
        "import spacy\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from plotly import tools\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "from sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import lightgbm as lgb\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, Concatenate, Add, Flatten, CuDNNLSTM\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.engine.topology import Layer\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np # linear algebra\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "pd.options.display.max_columns = 999\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# keras libraries\n",
        "from keras.models import Model, load_model,Sequential\n",
        "from keras.layers import Dense, Input, Dropout,Bidirectional, GRU, Activation, concatenate, Embedding, SpatialDropout1D\n",
        "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D ,GlobalMaxPool1D, GlobalAvgPool1D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras import layers\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/vnd.plotly.v1+html": "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>",
            "text/html": [
              "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "viX7O-jtgaVy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "050bd37c-fe49-4d8d-88d2-f983d228cf4b"
      },
      "cell_type": "code",
      "source": [
        "##======== Load text and tokenize ====================\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(u'A few days later, Abigail complained that Elizabeth was pinching her and tearing at her bowels')\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.tag_, token.dep_)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A DET DT det\n",
            "few ADJ JJ amod\n",
            "days NOUN NNS npadvmod\n",
            "later ADV RB advmod\n",
            ", PUNCT , punct\n",
            "Abigail PROPN NNP nsubj\n",
            "complained VERB VBD ROOT\n",
            "that ADP IN mark\n",
            "Elizabeth PROPN NNP nsubj\n",
            "was VERB VBD aux\n",
            "pinching VERB VBG ccomp\n",
            "her PRON PRP dobj\n",
            "and CCONJ CC cc\n",
            "tearing VERB VBG conj\n",
            "at ADP IN prep\n",
            "her ADJ PRP$ poss\n",
            "bowels NOUN NNS pobj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "feEuY8aQg3LE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "####======================= Define necessary libraries ========================\n",
        "def word_locate(sentence, location): \n",
        "    count_words = 0\n",
        "    count_chars = 2 #2 is to count for the two spaces in the beginning\n",
        "    for word in sentence.split():\n",
        "        count_words += 1\n",
        "        if location == count_chars:\n",
        "            return word, count_words\n",
        "        count_chars += len(word)\n",
        "        count_chars += 1 #for space\n",
        "        \n",
        "def curr_prev_sentence(sentence, loc):\n",
        "    current_sentence = \"\"\n",
        "    prev_sentence = \"\"\n",
        "    detect = 0\n",
        "    count = 0\n",
        "    for char in sentence:\n",
        "        count += 1\n",
        "        current_sentence += char\n",
        "        if char == \".\" and detect == 0:\n",
        "            prev_sentence = current_sentence \n",
        "            current_sentence = \"\"\n",
        "        if char == \".\" and detect == 1:\n",
        "            return current_sentence, prev_sentence\n",
        "        if count == loc:\n",
        "            detect = 1\n",
        "\n",
        "def find_subject(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            return token.text\n",
        "    return \"none\"            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k9x3mnHahn0g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "8f6b52e7-f9bd-4ee1-dcb6-fdfac4f650f9"
      },
      "cell_type": "code",
      "source": [
        "text1 = \"After a few years of almost no work -- although he was a guest star on Lou Grant and Charlie's Angels in the late 1970s, he once summed up the 1970s as 'I cried and did a lot of gardening' -- he was hired in 1979 for his best-known role, self-made millionaire Palmer Cortlandt on ABC's long-running soap opera All My Children. Initially hired for only one year, he remained on contract through 2009. For much of his first decade on the show, Palmer was a ruthless villain, totally possessive of his daughter, Nina and violently threatening his ex-wife Daisy with being attacked by dobermans when she came back from the dead.\"\n",
        "\n",
        "text2 = \"When onlookers expressed doubt, claiming that the Proctor family was well regarded in the community, the girl promptly came out of her trance and told them it was all for 'sport'. On March 29, 1692, Abigail Williams and Mercy Lewis again said they were being tormented by Elizabeth's spectre. A few days later, Abigail complained that Elizabeth was pinching her and tearing at her bowels, and said she saw Elizabeth's spectre as well as John's.\"\n",
        "\n",
        "current, prev = curr_prev_sentence(text2, 360)\n",
        "print(current)\n",
        "\n",
        "candidate = find_subject(current)\n",
        "print(candidate)\n",
        "\n",
        "word, loc = word_locate(text2, 360) \n",
        "print(word, \" \", loc)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " A few days later, Abigail complained that Elizabeth was pinching her and tearing at her bowels, and said she saw Elizabeth's spectre as well as John's.\n",
            "Abigail\n",
            "her   60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bYPmwZvbh4hv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "175e4c96-8ba2-4e64-a8d0-a6880c03cb34"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  sample_submission_stage_1.csv  test_stage_1.tsv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nzK3Yj7YiVIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e571534a-ed79-4122-cfd5-386aabbb956e"
      },
      "cell_type": "code",
      "source": [
        "!unzip test_stage_1.tsv.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test_stage_1.tsv.zip\n",
            "  inflating: test_stage_1.tsv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y84y7wFuicdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a5bf08f6-0b1b-4ad7-d3ee-703cf976997b"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "!git clone https://github.com/google-research-datasets/gap-coreference.git\n",
        "\n",
        "#!wget 'https://github.com/google-research-datasets/gap-coreference/blob/master/gap-development.tsv'\n",
        "\n",
        "#!files.download('https://github.com/google-research-datasets/gap-coreference/blob/master/gap-development.tsv') # then browse, select the files. It's then uploaded\n",
        "\n",
        "# uploaded is now a dict containing \"filename\" -> Content"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gap-coreference'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "Unpacking objects:   5% (1/19)   \rUnpacking objects:  10% (2/19)   \rUnpacking objects:  15% (3/19)   \rUnpacking objects:  21% (4/19)   \rUnpacking objects:  26% (5/19)   \rUnpacking objects:  31% (6/19)   \rUnpacking objects:  36% (7/19)   \rUnpacking objects:  42% (8/19)   \rUnpacking objects:  47% (9/19)   \rUnpacking objects:  52% (10/19)   \rUnpacking objects:  57% (11/19)   \rremote: Total 19 (delta 0), reused 0 (delta 0), pack-reused 19\u001b[K\n",
            "Unpacking objects:  63% (12/19)   \rUnpacking objects:  68% (13/19)   \rUnpacking objects:  73% (14/19)   \rUnpacking objects:  78% (15/19)   \rUnpacking objects:  84% (16/19)   \rUnpacking objects:  89% (17/19)   \rUnpacking objects:  94% (18/19)   \rUnpacking objects: 100% (19/19)   \rUnpacking objects: 100% (19/19), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OSj7ykj9kmPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "46dea167-f40b-4706-cc48-8c9011622011"
      },
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t sample_data\t\t\ttest_stage_1.tsv\n",
            "gap-coreference  sample_submission_stage_1.csv\ttest_stage_1.tsv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RRXhMeXYlBFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### ======================== load test_stage_1\n",
        "with open('test_stage_1.tsv') as tsvfile:\n",
        "    reader = csv.DictReader(tsvfile, dialect='excel-tab')\n",
        "    testA_X = []\n",
        "    testB_X = []\n",
        "    test_auX = []\n",
        "    test_ids = []\n",
        "    train_auX = [] #we do a small hack and fill up the aux train data twice, like train hopping \n",
        "    for row in reader:\n",
        "        text = row['Text']\n",
        "        textA = text.lower()\n",
        "        test_auX.append(text.lower())#test aux is half size of train aux\n",
        "        train_auX.append(text.lower()) #since test loop is running, why not fill up aux train in meantime \n",
        "        new_textA = textA\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(textA)):\n",
        "            if char_idx == int(row['A-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"person_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"pronom_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "        testA_X.append(new_textA)\n",
        "        textB = text.lower()\n",
        "        new_textB = textB\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(textB)):\n",
        "            if char_idx == int(row['B-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"person_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"pronom_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "        testB_X.append(new_textB)\n",
        "        test_ids.append(row['ID'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_Ov5j4slsIg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3e1cc38-5746-4b25-b9b0-57900facc6c5"
      },
      "cell_type": "code",
      "source": [
        "print(len(test_ids))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YaGUIpRsltZo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########=============================== Load gap-development.tsv ===================\n",
        "with open('/content/gap-coreference/gap-development.tsv') as tsvfile:\n",
        "    reader = csv.DictReader(tsvfile, dialect='excel-tab')\n",
        "#     print(*reader)\n",
        "    train_X = []\n",
        "    train_y = []\n",
        "    for row in reader:\n",
        "#         print(row)\n",
        "        text = row[\"Text\"]\n",
        "        text = text.lower()\n",
        "        train_auX.append(text)\n",
        "        new_textA = text\n",
        "        labelA = 0\n",
        "        labelB = 0\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(text)):\n",
        "            if char_idx == int(row['A-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"person_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"pronom_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "        if row['A-coref'] == 'TRUE':\n",
        "            labelA = 1\n",
        "        train_X.append(new_textA)\n",
        "        train_y.append(labelA)\n",
        "        new_textB = text\n",
        "        label = 0\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(text)):\n",
        "            if char_idx == int(row['B-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"person_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"pronom_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "        if row['B-coref'] == 'TRUE':\n",
        "            labelB = 1\n",
        "        train_X.append(new_textB)\n",
        "        train_y.append(labelB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xzHyV88Wl58u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd689531-ca06-4dda-8c19-2a15af59d66c"
      },
      "cell_type": "code",
      "source": [
        "print(len(train_X))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vGjAFoiqpKM6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###============= Tokenize \n",
        "maxlen = 220\n",
        "embed_size = 500\n",
        "max_features = 7000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62w66gGmpPia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f71ccd22-db2d-4607-8209-c11371d1ae72"
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer_list = list(train_X)\n",
        "tokenizer.fit_on_texts(tokenizer_list)\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "testA_X = tokenizer.texts_to_sequences(testA_X)\n",
        "testB_X = tokenizer.texts_to_sequences(testB_X)\n",
        "test_auX = tokenizer.texts_to_sequences(test_auX)\n",
        "train_auX = tokenizer.texts_to_sequences(train_auX)\n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "testA_X = pad_sequences(testA_X, maxlen=maxlen)\n",
        "testB_X = pad_sequences(testB_X, maxlen=maxlen)\n",
        "test_auX = pad_sequences(test_auX, maxlen=maxlen)\n",
        "train_auX = pad_sequences(train_auX, maxlen=maxlen)\n",
        "\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "max_features = len(word_index)\n",
        "\n",
        "print(max_features)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mKyYwJgxpfHj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatible with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "      \n",
        "      \n",
        "class AttentionWithContext(Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qZQOpj56prTL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_y = np.asarray(train_y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "142jGoYkpvny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##==========================Define CuDNNGRU model\n",
        "def get_model():\n",
        "  inp1 = Input(shape=(maxlen,))\n",
        "  inp2 = Input(shape=(maxlen,))\n",
        "\n",
        "  model1_out = Embedding(max_features, embed_size)(inp1)\n",
        "  model1_out = Bidirectional(CuDNNGRU(256, return_sequences=True))(model1_out)\n",
        "  model1_out = AttentionWithContext()(model1_out)\n",
        "  model1_out = Dropout(0.1)(model1_out)\n",
        "\n",
        "  model2_out = Embedding(max_features, embed_size)(inp2)\n",
        "  model2_out = Bidirectional(CuDNNGRU(256, return_sequences=True))(model2_out)\n",
        "  model2_out = AttentionWithContext()(model2_out)\n",
        "  model2_out = Dropout(0.1)(model2_out)\n",
        "\n",
        "  merged_out = keras.layers.Concatenate(axis=1)([model1_out, model2_out])\n",
        "\n",
        "  merged_out = Dense(32, activation=\"relu\")(merged_out)\n",
        "  merged_out = Dropout(0.1)(merged_out)\n",
        "  \n",
        "  merged_out = Dense(1, activation=\"sigmoid\")(merged_out)\n",
        "  model = Model(inputs=[inp1,inp2], outputs=merged_out)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e6a6eWRaBcoH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##==========================Define LSTM model\n",
        "def get_model_1():\n",
        "  inp1 = Input(shape=(maxlen,))\n",
        "  inp2 = Input(shape=(maxlen,))\n",
        "\n",
        "  model1_out = Embedding(max_features, embed_size)(inp1)\n",
        "  model1_out = Bidirectional(LSTM(256, return_sequences=True))(model1_out)\n",
        "  model1_out = AttentionWithContext()(model1_out)\n",
        "  model1_out = Dropout(0.1)(model1_out)\n",
        "\n",
        "  model2_out = Embedding(max_features, embed_size)(inp2)\n",
        "  model2_out = Bidirectional(LSTM(256, return_sequences=True))(model2_out)\n",
        "  model2_out = AttentionWithContext()(model2_out)\n",
        "  model2_out = Dropout(0.1)(model2_out)\n",
        "\n",
        "  merged_out = keras.layers.Concatenate(axis=1)([model1_out, model2_out])\n",
        "\n",
        "  merged_out = Dense(32, activation=\"relu\")(merged_out)\n",
        "  merged_out = Dropout(0.1)(merged_out)\n",
        "  \n",
        "  merged_out = Dense(1, activation=\"sigmoid\")(merged_out)\n",
        "  model = Model(inputs=[inp1,inp2], outputs=merged_out)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ifhlKUYBtmhB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model_gru():\n",
        "    inp = Input(shape=(maxlen, ))\n",
        "    x = Embedding(max_features, embed_size)(inp)\n",
        "    x = SpatialDropout1D(0.2)(x) # 0.2 -> 0.1\n",
        "    x = Bidirectional(GRU(80, return_sequences=True, activation='relu', dropout=0.1, recurrent_dropout=0.0))(x) # 80 -> 85\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
        "    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xfz7MVMytVwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "outputId": "d15336c3-c59b-4626-d56e-e488d3c684be"
      },
      "cell_type": "code",
      "source": [
        "########===========================CuDNNGRU ================\n",
        "model = get_model()\n",
        "# model = get_model_gru()\n",
        "print(model.summary())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 220, 500)     11121500    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 220, 500)     11121500    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 220, 512)     1164288     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 220, 512)     1164288     embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_1 (Atten (None, 512)          263168      bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_2 (Atten (None, 512)          263168      bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           attention_with_context_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512)          0           attention_with_context_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1024)         0           dropout_1[0][0]                  \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32)           32800       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            33          dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 25,130,745\n",
            "Trainable params: 25,130,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3vlc3awwp5vJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1927
        },
        "outputId": "cca8f4f6-00ca-48b9-cbcf-30c672df2893"
      },
      "cell_type": "code",
      "source": [
        "model.fit([train_X, train_auX], train_y, batch_size=512, epochs=50, validation_data=([train_X,train_auX], train_y))\n",
        "\n",
        "\n",
        "# model.fit(train_X, train_y, epochs=20, batch_size=32, validation_split=0.1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 4000 samples, validate on 4000 samples\n",
            "Epoch 1/50\n",
            "4000/4000 [==============================] - 20s 5ms/step - loss: 0.6899 - acc: 0.5502 - val_loss: 0.6877 - val_acc: 0.5503\n",
            "Epoch 2/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.6886 - acc: 0.5503 - val_loss: 0.6852 - val_acc: 0.5503\n",
            "Epoch 3/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.6839 - acc: 0.5503 - val_loss: 0.6737 - val_acc: 0.5503\n",
            "Epoch 4/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.6565 - acc: 0.5945 - val_loss: 0.5986 - val_acc: 0.7032\n",
            "Epoch 5/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.5804 - acc: 0.6980 - val_loss: 0.5054 - val_acc: 0.7425\n",
            "Epoch 6/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.5181 - acc: 0.7173 - val_loss: 0.4797 - val_acc: 0.7483\n",
            "Epoch 7/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.4802 - acc: 0.7185 - val_loss: 0.4295 - val_acc: 0.7562\n",
            "Epoch 8/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.4348 - acc: 0.7228 - val_loss: 0.3880 - val_acc: 0.7635\n",
            "Epoch 9/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.3948 - acc: 0.7490 - val_loss: 0.3622 - val_acc: 0.7888\n",
            "Epoch 10/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.3639 - acc: 0.7840 - val_loss: 0.3197 - val_acc: 0.8403\n",
            "Epoch 11/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.3106 - acc: 0.8492 - val_loss: 0.2269 - val_acc: 0.9163\n",
            "Epoch 12/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.2210 - acc: 0.9122 - val_loss: 0.1520 - val_acc: 0.9460\n",
            "Epoch 13/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.1503 - acc: 0.9442 - val_loss: 0.0848 - val_acc: 0.9693\n",
            "Epoch 14/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0984 - acc: 0.9650 - val_loss: 0.0558 - val_acc: 0.9825\n",
            "Epoch 15/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0644 - acc: 0.9773 - val_loss: 0.0351 - val_acc: 0.9897\n",
            "Epoch 16/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0552 - acc: 0.9835 - val_loss: 0.0512 - val_acc: 0.9858\n",
            "Epoch 17/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0584 - acc: 0.9800 - val_loss: 0.0321 - val_acc: 0.9893\n",
            "Epoch 18/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0431 - acc: 0.9855 - val_loss: 0.0180 - val_acc: 0.9947\n",
            "Epoch 19/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0230 - acc: 0.9942 - val_loss: 0.0145 - val_acc: 0.9965\n",
            "Epoch 20/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0159 - acc: 0.9952 - val_loss: 0.0066 - val_acc: 0.9987\n",
            "Epoch 21/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0092 - acc: 0.9970 - val_loss: 0.0035 - val_acc: 0.9995\n",
            "Epoch 22/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0062 - acc: 0.9978 - val_loss: 0.0027 - val_acc: 1.0000\n",
            "Epoch 23/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 24/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0037 - val_acc: 0.9992\n",
            "Epoch 25/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0043 - val_acc: 0.9987\n",
            "Epoch 26/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0190 - acc: 0.9937 - val_loss: 0.0103 - val_acc: 0.9972\n",
            "Epoch 27/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0131 - acc: 0.9965 - val_loss: 0.0058 - val_acc: 0.9987\n",
            "Epoch 28/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.0022 - val_acc: 0.9995\n",
            "Epoch 29/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0017 - val_acc: 0.9995\n",
            "Epoch 30/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 7.6858e-04 - val_acc: 1.0000\n",
            "Epoch 31/50\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 3.5806e-04 - val_acc: 1.0000\n",
            "Epoch 32/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 3.9136e-04 - acc: 1.0000 - val_loss: 2.6036e-04 - val_acc: 1.0000\n",
            "Epoch 33/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 3.5321e-04 - acc: 1.0000 - val_loss: 2.1301e-04 - val_acc: 1.0000\n",
            "Epoch 34/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 2.5656e-04 - acc: 1.0000 - val_loss: 1.7854e-04 - val_acc: 1.0000\n",
            "Epoch 35/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 2.4566e-04 - acc: 1.0000 - val_loss: 1.4267e-04 - val_acc: 1.0000\n",
            "Epoch 36/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 2.5442e-04 - acc: 1.0000 - val_loss: 1.1854e-04 - val_acc: 1.0000\n",
            "Epoch 37/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 2.2084e-04 - acc: 1.0000 - val_loss: 9.9385e-05 - val_acc: 1.0000\n",
            "Epoch 38/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 1.5356e-04 - acc: 1.0000 - val_loss: 9.0129e-05 - val_acc: 1.0000\n",
            "Epoch 39/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 1.6071e-04 - acc: 1.0000 - val_loss: 7.7658e-05 - val_acc: 1.0000\n",
            "Epoch 40/50\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 1.3863e-04 - acc: 1.0000 - val_loss: 7.0694e-05 - val_acc: 1.0000\n",
            "Epoch 41/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 1.1206e-04 - acc: 1.0000 - val_loss: 6.4611e-05 - val_acc: 1.0000\n",
            "Epoch 42/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 1.2294e-04 - acc: 1.0000 - val_loss: 5.9678e-05 - val_acc: 1.0000\n",
            "Epoch 43/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 9.3778e-05 - acc: 1.0000 - val_loss: 5.5375e-05 - val_acc: 1.0000\n",
            "Epoch 44/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 8.8439e-05 - acc: 1.0000 - val_loss: 5.1949e-05 - val_acc: 1.0000\n",
            "Epoch 45/50\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 8.7642e-05 - acc: 1.0000 - val_loss: 4.8772e-05 - val_acc: 1.0000\n",
            "Epoch 46/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 8.8326e-05 - acc: 1.0000 - val_loss: 4.5959e-05 - val_acc: 1.0000\n",
            "Epoch 47/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 8.4107e-05 - acc: 1.0000 - val_loss: 4.3451e-05 - val_acc: 1.0000\n",
            "Epoch 48/50\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 7.3419e-05 - acc: 1.0000 - val_loss: 4.1017e-05 - val_acc: 1.0000\n",
            "Epoch 49/50\n",
            "4000/4000 [==============================] - 15s 4ms/step - loss: 7.1191e-05 - acc: 1.0000 - val_loss: 3.8906e-05 - val_acc: 1.0000\n",
            "Epoch 50/50\n",
            "4000/4000 [==============================] - 16s 4ms/step - loss: 6.8662e-05 - acc: 1.0000 - val_loss: 3.6881e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f68c99251d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "MjZt9hhYp_h7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "31200387-0c86-4bc8-fb91-11e51b23f8ae"
      },
      "cell_type": "code",
      "source": [
        "pred_valA_y = model.predict([testA_X,test_auX], batch_size=512, verbose=1)\n",
        "pred_valB_y = model.predict([testB_X,test_auX], batch_size=512, verbose=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 2s 1ms/step\n",
            "2000/2000 [==============================] - 2s 956us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yZXHWKjvxNzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1819da9f-567e-4130-81a9-ff590a879483"
      },
      "cell_type": "code",
      "source": [
        "print(len(pred_valB_y), \" \", len(pred_valA_y))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000   2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I4-i7Xsac6qI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "de3700ad-8761-43c5-c19f-24d29077d3c4"
      },
      "cell_type": "code",
      "source": [
        "####============= Second Model: LSTM =======================\n",
        "model = get_model_1()\n",
        "# model = get_model_gru()\n",
        "print(model.summary())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 220, 500)     11121500    input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 220, 500)     11121500    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 220, 512)     1550336     embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 220, 512)     1550336     embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_3 (Atten (None, 512)          263168      bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_4 (Atten (None, 512)          263168      bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 512)          0           attention_with_context_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 512)          0           attention_with_context_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1024)         0           dropout_4[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           32800       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            33          dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 25,902,841\n",
            "Trainable params: 25,902,841\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qnQOf4BCdEus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1873
        },
        "outputId": "91aaf9c0-a014-4dc3-aa09-3e9d30fec59c"
      },
      "cell_type": "code",
      "source": [
        "model.fit([train_X, train_auX], train_y, batch_size=512, epochs=50, validation_data=([train_X,train_auX], train_y))\n",
        "\n",
        "\n",
        "# model.fit(train_X, train_y, epochs=20, batch_size=32, validation_split=0.1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4000 samples, validate on 4000 samples\n",
            "Epoch 1/50\n",
            "4000/4000 [==============================] - 44s 11ms/step - loss: 0.6906 - acc: 0.5465 - val_loss: 0.6919 - val_acc: 0.5503\n",
            "Epoch 2/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.6883 - acc: 0.5503 - val_loss: 0.6861 - val_acc: 0.5503\n",
            "Epoch 3/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.6852 - acc: 0.5503 - val_loss: 0.6760 - val_acc: 0.5508\n",
            "Epoch 4/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.6572 - acc: 0.6488 - val_loss: 0.6530 - val_acc: 0.5820\n",
            "Epoch 5/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.5823 - acc: 0.6878 - val_loss: 0.6028 - val_acc: 0.7012\n",
            "Epoch 6/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.5388 - acc: 0.7135 - val_loss: 0.4895 - val_acc: 0.7438\n",
            "Epoch 7/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.4947 - acc: 0.7273 - val_loss: 0.4724 - val_acc: 0.7513\n",
            "Epoch 8/50\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 0.4674 - acc: 0.7247 - val_loss: 0.4096 - val_acc: 0.7722\n",
            "Epoch 9/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.4230 - acc: 0.7467 - val_loss: 0.3598 - val_acc: 0.8053\n",
            "Epoch 10/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.3563 - acc: 0.8165 - val_loss: 0.2788 - val_acc: 0.8922\n",
            "Epoch 11/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.2559 - acc: 0.8955 - val_loss: 0.1471 - val_acc: 0.9542\n",
            "Epoch 12/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.1536 - acc: 0.9488 - val_loss: 0.0810 - val_acc: 0.9738\n",
            "Epoch 13/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0918 - acc: 0.9675 - val_loss: 0.0732 - val_acc: 0.9772\n",
            "Epoch 14/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0618 - acc: 0.9815 - val_loss: 0.0298 - val_acc: 0.9930\n",
            "Epoch 15/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0462 - acc: 0.9867 - val_loss: 0.0242 - val_acc: 0.9952\n",
            "Epoch 16/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0292 - acc: 0.9932 - val_loss: 0.0215 - val_acc: 0.9938\n",
            "Epoch 17/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0221 - acc: 0.9942 - val_loss: 0.0087 - val_acc: 0.9982\n",
            "Epoch 18/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0115 - acc: 0.9965 - val_loss: 0.0071 - val_acc: 0.9977\n",
            "Epoch 19/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0090 - acc: 0.9970 - val_loss: 0.0062 - val_acc: 0.9980\n",
            "Epoch 20/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0069 - val_acc: 0.9992\n",
            "Epoch 21/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0076 - val_acc: 0.9985\n",
            "Epoch 22/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0081 - val_acc: 0.9985\n",
            "Epoch 23/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0084 - acc: 0.9985 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 24/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0042 - acc: 0.9992 - val_loss: 0.0027 - val_acc: 1.0000\n",
            "Epoch 25/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 9.9454e-04 - val_acc: 1.0000\n",
            "Epoch 26/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 7.2951e-04 - val_acc: 1.0000\n",
            "Epoch 27/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 7.6108e-04 - acc: 1.0000 - val_loss: 5.6830e-04 - val_acc: 1.0000\n",
            "Epoch 28/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 9.0429e-04 - acc: 0.9997 - val_loss: 5.0878e-04 - val_acc: 1.0000\n",
            "Epoch 29/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 5.6873e-04 - acc: 1.0000 - val_loss: 3.2298e-04 - val_acc: 1.0000\n",
            "Epoch 30/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 4.4971e-04 - acc: 1.0000 - val_loss: 2.6913e-04 - val_acc: 1.0000\n",
            "Epoch 31/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 4.7494e-04 - acc: 1.0000 - val_loss: 2.1891e-04 - val_acc: 1.0000\n",
            "Epoch 32/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 2.7872e-04 - acc: 1.0000 - val_loss: 1.8053e-04 - val_acc: 1.0000\n",
            "Epoch 33/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 2.7325e-04 - acc: 1.0000 - val_loss: 1.5540e-04 - val_acc: 1.0000\n",
            "Epoch 34/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 2.3409e-04 - acc: 1.0000 - val_loss: 1.3655e-04 - val_acc: 1.0000\n",
            "Epoch 35/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 2.2818e-04 - acc: 1.0000 - val_loss: 1.2205e-04 - val_acc: 1.0000\n",
            "Epoch 36/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 2.3679e-04 - acc: 1.0000 - val_loss: 1.0869e-04 - val_acc: 1.0000\n",
            "Epoch 37/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 1.7209e-04 - acc: 1.0000 - val_loss: 9.8416e-05 - val_acc: 1.0000\n",
            "Epoch 38/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 1.6432e-04 - acc: 1.0000 - val_loss: 8.9554e-05 - val_acc: 1.0000\n",
            "Epoch 39/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 1.3187e-04 - acc: 1.0000 - val_loss: 8.1886e-05 - val_acc: 1.0000\n",
            "Epoch 40/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 1.1965e-04 - acc: 1.0000 - val_loss: 7.5581e-05 - val_acc: 1.0000\n",
            "Epoch 41/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 1.4935e-04 - acc: 1.0000 - val_loss: 6.9993e-05 - val_acc: 1.0000\n",
            "Epoch 42/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 1.2837e-04 - acc: 1.0000 - val_loss: 6.5409e-05 - val_acc: 1.0000\n",
            "Epoch 43/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 1.1013e-04 - acc: 1.0000 - val_loss: 6.0652e-05 - val_acc: 1.0000\n",
            "Epoch 44/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 1.1067e-04 - acc: 1.0000 - val_loss: 5.6363e-05 - val_acc: 1.0000\n",
            "Epoch 45/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 9.2006e-05 - acc: 1.0000 - val_loss: 5.2666e-05 - val_acc: 1.0000\n",
            "Epoch 46/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 9.3572e-05 - acc: 1.0000 - val_loss: 4.9274e-05 - val_acc: 1.0000\n",
            "Epoch 47/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 8.4107e-05 - acc: 1.0000 - val_loss: 4.6347e-05 - val_acc: 1.0000\n",
            "Epoch 48/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 8.9787e-05 - acc: 1.0000 - val_loss: 4.4570e-05 - val_acc: 1.0000\n",
            "Epoch 49/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 8.4098e-05 - acc: 1.0000 - val_loss: 4.1624e-05 - val_acc: 1.0000\n",
            "Epoch 50/50\n",
            "4000/4000 [==============================] - 38s 9ms/step - loss: 6.7778e-05 - acc: 1.0000 - val_loss: 3.8710e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f68c4564470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "uARriHAQdEoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0aa28851-53f4-47de-837d-63512ae1a1af"
      },
      "cell_type": "code",
      "source": [
        "pred_valA_y_2 = model.predict([testA_X,test_auX], batch_size=512, verbose=1)\n",
        "pred_valB_y_2 = model.predict([testB_X,test_auX], batch_size=512, verbose=1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 5s 3ms/step\n",
            "2000/2000 [==============================] - 5s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uhpjPeC2dU9z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_vA_y = (pred_valA_y + pred_valA_y_2)/2.0\n",
        "pred_vB_y = (pred_valB_y + pred_valB_y_2)/2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i0dfiT8nxRO5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df = pd.DataFrame({\"ID\":test_ids})\n",
        "out_df['A'] = [max(float(val),0.33) for val in list(pred_vA_y)]\n",
        "out_df['B'] = [max(float(val),0.33) for val in list(pred_vB_y)]\n",
        "out_df['NEITHER'] = [max((1-float(val)),0.33) for val in list(pred_vA_y)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gVJuG_wZT7JT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "f6a0d4fd-222a-4a11-948f-be3d94234f5f"
      },
      "cell_type": "code",
      "source": [
        "out_df.head(10)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>NEITHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>0.999966</td>\n",
              "      <td>0.999831</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.923551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>0.981134</td>\n",
              "      <td>0.999990</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.529836</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>development-6</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999996</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>development-7</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.999959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>development-8</td>\n",
              "      <td>0.492753</td>\n",
              "      <td>0.999303</td>\n",
              "      <td>0.507247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development-9</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.990864</td>\n",
              "      <td>0.999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>development-10</td>\n",
              "      <td>0.999991</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID         A         B   NEITHER\n",
              "0   development-1  0.999966  0.999831  0.330000\n",
              "1   development-2  0.330000  0.330000  0.923551\n",
              "2   development-3  0.981134  0.999990  0.330000\n",
              "3   development-4  0.330000  0.330000  1.000000\n",
              "4   development-5  0.330000  0.529836  1.000000\n",
              "5   development-6  1.000000  0.999996  0.330000\n",
              "6   development-7  0.330000  0.330000  0.999959\n",
              "7   development-8  0.492753  0.999303  0.507247\n",
              "8   development-9  0.330000  0.990864  0.999999\n",
              "9  development-10  0.999991  0.330000  0.330000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "-bwRBhWkxZ-i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df.to_csv(\"submission_8.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Xj6CAC-ffP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5255d709-5210-4780-c4b6-f2acdb282261"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t sample_submission_stage_1.csv\ttest_stage_1.tsv.zip\n",
            "gap-coreference  submission_8.csv\n",
            "sample_data\t test_stage_1.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uYrFmuMbxenQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "426e721d-c5ce-44d1-e3bc-367478018d3e"
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution '"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " answers_1.csv\n",
            " answers.csv\n",
            " gendered-pronoun-resolution\n",
            "'Gendered Pronoun Resolution: Version-08.ipynb'\n",
            " submission_1.csv\n",
            " submission_2.csv\n",
            " submission_3.csv\n",
            " submission_4.csv\n",
            " submission_5.csv\n",
            "'Top 3 NLP Libraries Tutorial( NLTK+spaCy+Gensim).ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DruSyLnUxov-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df.to_csv(\"/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /submission_8.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Gr5OpOHg9TW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "answers = pd.read_csv('/content/submission_8.csv', dtype={'A-coref': int, 'B-coref': int})\n",
        "answers.rename(columns={'A-coref': 'A', 'B-coref': 'B'}, inplace=True)\n",
        "answers['NEITHER'] = abs(answers.eval('1 - A - B'))\n",
        "answers[['ID', 'A', 'B', 'NEITHER']].to_csv(\"submission_9.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "isE51rP7dXrB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answers[['ID', 'A', 'B', 'NEITHER']].to_csv(\"/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /submission_9.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jCzt7VFVpFKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "142caf8c-abc9-4eff-ae76-b1a9a5b88af5"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t sample_submission_stage_1.csv\ttest_stage_1.tsv\n",
            "gap-coreference  submission_8.csv\t\ttest_stage_1.tsv.zip\n",
            "sample_data\t submission_9.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eytJsrc1otwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "1742a031-01d9-43bc-89ae-fe3bdccfe986"
      },
      "cell_type": "code",
      "source": [
        "answers.head(10)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>NEITHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>0.999966</td>\n",
              "      <td>0.999831</td>\n",
              "      <td>0.999798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>0.981134</td>\n",
              "      <td>0.999990</td>\n",
              "      <td>0.981123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.529836</td>\n",
              "      <td>0.140164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>development-6</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999996</td>\n",
              "      <td>0.999996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>development-7</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>development-8</td>\n",
              "      <td>0.492753</td>\n",
              "      <td>0.999303</td>\n",
              "      <td>0.492055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development-9</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.990864</td>\n",
              "      <td>0.320864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>development-10</td>\n",
              "      <td>0.999991</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.329991</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID         A         B   NEITHER\n",
              "0   development-1  0.999966  0.999831  0.999798\n",
              "1   development-2  0.330000  0.330000  0.340000\n",
              "2   development-3  0.981134  0.999990  0.981123\n",
              "3   development-4  0.330000  0.330000  0.340000\n",
              "4   development-5  0.330000  0.529836  0.140164\n",
              "5   development-6  1.000000  0.999996  0.999996\n",
              "6   development-7  0.330000  0.330000  0.340000\n",
              "7   development-8  0.492753  0.999303  0.492055\n",
              "8   development-9  0.330000  0.990864  0.320864\n",
              "9  development-10  0.999991  0.330000  0.329991"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "uuEZiS8Ax62F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "b61abfe8-7530-4351-99c8-d873e88bdd31"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c gendered-pronoun-resolution -f submission_9.csv -m \"V-09\""
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "100% 112k/112k [00:02<00:00, 50.7kB/s]\n",
            "Successfully submitted to Gendered Pronoun Resolution"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "77C2wmuuyI-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}