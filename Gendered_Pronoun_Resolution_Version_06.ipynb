{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gendered Pronoun Resolution: Version-06.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rezwanh001/Kaggle-Competition-Gendered-Pronoun-Resolution/blob/master/Gendered_Pronoun_Resolution_Version_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OaHnm9HUab0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3cfda184-7f77-43a2-a2cc-bf7fe9d610cc"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kqeNH_3Raktz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import pprint\n",
        "# import tensorflow as tf\n",
        "\n",
        "# if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "#   print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "# else:\n",
        "#   tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "#   print ('TPU address is', tpu_address)\n",
        "\n",
        "#   with tf.Session(tpu_address) as session:\n",
        "#     devices = session.list_devices()\n",
        "    \n",
        "#   print('TPU devices:')\n",
        "#   pprint.pprint(devices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xWirk_Vga7sj",
        "colab_type": "code",
        "outputId": "c14c4a62-5148-4553-87ca-e125466772b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TnCcxAAmbEUV",
        "colab_type": "code",
        "outputId": "709539e4-25ba-4c60-c803-e32a38ede429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "cell_type": "code",
      "source": [
        "# to access kaggle datasets\n",
        "!pip install kaggle\n",
        "\n",
        "# Math operations\n",
        "!pip install numpy==1.15.0\n",
        "\n",
        "#\n",
        "!pip install https://github.com/fchollet/keras/archive/cudnn.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.2)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.0.1)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.23)\n",
            "Requirement already satisfied: numpy==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Collecting https://github.com/fchollet/keras/archive/cudnn.zip\n",
            "\u001b[31m  HTTP error 404 while getting https://github.com/fchollet/keras/archive/cudnn.zip\u001b[0m\n",
            "\u001b[31m  Could not install requirement https://github.com/fchollet/keras/archive/cudnn.zip because of error 404 Client Error: Not Found for url: https://codeload.github.com/keras-team/keras/zip/cudnn\u001b[0m\n",
            "\u001b[31mCould not install requirement https://github.com/fchollet/keras/archive/cudnn.zip because of HTTP error 404 Client Error: Not Found for url: https://codeload.github.com/keras-team/keras/zip/cudnn for URL https://github.com/fchollet/keras/archive/cudnn.zip\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VAxLPHMpbJlJ",
        "colab_type": "code",
        "outputId": "4270fa27-2b47-44c3-a36e-9e908b17a9f8",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "# Colab's file access feature\n",
        "from google.colab import files\n",
        "\n",
        "# retrieve upload file\n",
        "uploaded = files.upload()\n",
        "\n",
        "#print results\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.jason into the folder where the API expects to to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/kaggle/kaggle.json "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-17788ef8-c743-4e87-bb13-4dcd2cebf38c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-17788ef8-c743-4e87-bb13-4dcd2cebf38c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 65 bytes\n",
            "chmod: cannot access '/root/kaggle/kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_c-nSdN6bNKM",
        "colab_type": "code",
        "outputId": "0328822c-7840-43de-a6b5-a19744e43571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "# list competitions\n",
        "!kaggle competitions list\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "ref                                            deadline             category            reward  teamCount  userHasEntered  \n",
            "---------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "digit-recognizer                               2030-01-01 00:00:00  Getting Started  Knowledge       2490           False  \n",
            "titanic                                        2030-01-01 00:00:00  Getting Started  Knowledge       9877            True  \n",
            "house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started  Knowledge       4083           False  \n",
            "imagenet-object-localization-challenge         2029-12-31 07:00:00  Research         Knowledge         35           False  \n",
            "competitive-data-science-predict-future-sales  2019-12-31 23:59:00  Playground           Kudos       2385           False  \n",
            "two-sigma-financial-news                       2019-07-15 23:59:00  Featured          $100,000       2927           False  \n",
            "LANL-Earthquake-Prediction                     2019-06-03 23:59:00  Research           $50,000       1278            True  \n",
            "tmdb-box-office-prediction                     2019-05-30 23:59:00  Playground       Knowledge        255           False  \n",
            "dont-overfit-ii                                2019-05-07 23:59:00  Playground            Swag        718           False  \n",
            "gendered-pronoun-resolution                    2019-04-22 23:59:00  Research           $25,000        239            True  \n",
            "santander-customer-transaction-prediction      2019-04-10 23:59:00  Featured           $65,000       2029           False  \n",
            "womens-machine-learning-competition-2019       2019-04-09 23:59:00  Featured           $25,000         83           False  \n",
            "mens-machine-learning-competition-2019         2019-04-08 23:59:00  Featured           $25,000        133           False  \n",
            "histopathologic-cancer-detection               2019-03-30 23:59:00  Playground       Knowledge        698           False  \n",
            "petfinder-adoption-prediction                  2019-03-28 23:59:00  Featured           $25,000       1278           False  \n",
            "vsb-power-line-fault-detection                 2019-03-21 23:59:00  Featured           $25,000       1024           False  \n",
            "microsoft-malware-prediction                   2019-03-13 23:59:00  Research           $25,000       1877           False  \n",
            "humpback-whale-identification                  2019-02-28 23:59:00  Featured           $25,000       2055           False  \n",
            "elo-merchant-category-recommendation           2019-02-26 23:59:00  Featured           $50,000       4106            True  \n",
            "ga-customer-revenue-prediction                 2019-02-21 20:04:00  Featured           $45,000       1100            True  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rQwJfvLnbUp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "bd451e6f-65e5-460a-e6d9-165548aa74ae"
      },
      "cell_type": "code",
      "source": [
        "#download gendered-pronoun-resolution data\n",
        "!kaggle competitions download -c gendered-pronoun-resolution"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading sample_submission_stage_1.csv to /content\n",
            "  0% 0.00/79.0k [00:00<?, ?B/s]\n",
            "100% 79.0k/79.0k [00:00<00:00, 69.5MB/s]\n",
            "Downloading test_stage_1.tsv.zip to /content\n",
            "  0% 0.00/425k [00:00<?, ?B/s]\n",
            "100% 425k/425k [00:00<00:00, 60.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RS-qcHXgf96P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf07c4d8-2154-4271-88cf-d808d436249d"
      },
      "cell_type": "code",
      "source": [
        "###=============== Import necessary Libraries ==================\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import string\n",
        "import keras\n",
        "from pandas.io.json import json_normalize\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "from math import floor\n",
        "import spacy\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from plotly import tools\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "from sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import lightgbm as lgb\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, Concatenate, Add, Flatten, CuDNNLSTM\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.engine.topology import Layer\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np # linear algebra\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "pd.options.display.max_columns = 999\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# keras libraries\n",
        "from keras.models import Model, load_model,Sequential\n",
        "from keras.layers import Dense, Input, Dropout,Bidirectional, GRU, Activation, concatenate, Embedding, SpatialDropout1D\n",
        "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D ,GlobalMaxPool1D, GlobalAvgPool1D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras import layers\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/vnd.plotly.v1+html": "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>",
            "text/html": [
              "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "viX7O-jtgaVy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "01d7824d-49b4-495d-c2e8-8615f7dc0be7"
      },
      "cell_type": "code",
      "source": [
        "##======== Load text and tokenize ====================\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(u'A few days later, Abigail complained that Elizabeth was pinching her and tearing at her bowels')\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.tag_, token.dep_)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A DET DT det\n",
            "few ADJ JJ amod\n",
            "days NOUN NNS npadvmod\n",
            "later ADV RB advmod\n",
            ", PUNCT , punct\n",
            "Abigail PROPN NNP nsubj\n",
            "complained VERB VBD ROOT\n",
            "that ADP IN mark\n",
            "Elizabeth PROPN NNP nsubj\n",
            "was VERB VBD aux\n",
            "pinching VERB VBG ccomp\n",
            "her PRON PRP dobj\n",
            "and CCONJ CC cc\n",
            "tearing VERB VBG conj\n",
            "at ADP IN prep\n",
            "her ADJ PRP$ poss\n",
            "bowels NOUN NNS pobj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "feEuY8aQg3LE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "####======================= Define necessary libraries ========================\n",
        "def word_locate(sentence, location): \n",
        "    count_words = 0\n",
        "    count_chars = 2 #2 is to count for the two spaces in the beginning\n",
        "    for word in sentence.split():\n",
        "        count_words += 1\n",
        "        if location == count_chars:\n",
        "            return word, count_words\n",
        "        count_chars += len(word)\n",
        "        count_chars += 1 #for space\n",
        "        \n",
        "def curr_prev_sentence(sentence, loc):\n",
        "    current_sentence = \"\"\n",
        "    prev_sentence = \"\"\n",
        "    detect = 0\n",
        "    count = 0\n",
        "    for char in sentence:\n",
        "        count += 1\n",
        "        current_sentence += char\n",
        "        if char == \".\" and detect == 0:\n",
        "            prev_sentence = current_sentence \n",
        "            current_sentence = \"\"\n",
        "        if char == \".\" and detect == 1:\n",
        "            return current_sentence, prev_sentence\n",
        "        if count == loc:\n",
        "            detect = 1\n",
        "\n",
        "def find_subject(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            return token.text\n",
        "    return \"none\"            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k9x3mnHahn0g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "4d439416-2bec-4398-a560-7d44ae60cb67"
      },
      "cell_type": "code",
      "source": [
        "text1 = \"After a few years of almost no work -- although he was a guest star on Lou Grant and Charlie's Angels in the late 1970s, he once summed up the 1970s as 'I cried and did a lot of gardening' -- he was hired in 1979 for his best-known role, self-made millionaire Palmer Cortlandt on ABC's long-running soap opera All My Children. Initially hired for only one year, he remained on contract through 2009. For much of his first decade on the show, Palmer was a ruthless villain, totally possessive of his daughter, Nina and violently threatening his ex-wife Daisy with being attacked by dobermans when she came back from the dead.\"\n",
        "\n",
        "text2 = \"When onlookers expressed doubt, claiming that the Proctor family was well regarded in the community, the girl promptly came out of her trance and told them it was all for 'sport'. On March 29, 1692, Abigail Williams and Mercy Lewis again said they were being tormented by Elizabeth's spectre. A few days later, Abigail complained that Elizabeth was pinching her and tearing at her bowels, and said she saw Elizabeth's spectre as well as John's.\"\n",
        "\n",
        "current, prev = curr_prev_sentence(text2, 360)\n",
        "print(current)\n",
        "\n",
        "candidate = find_subject(current)\n",
        "print(candidate)\n",
        "\n",
        "word, loc = word_locate(text2, 360) \n",
        "print(word, \" \", loc)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " A few days later, Abigail complained that Elizabeth was pinching her and tearing at her bowels, and said she saw Elizabeth's spectre as well as John's.\n",
            "Abigail\n",
            "her   60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bYPmwZvbh4hv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2b9bc629-b267-4948-8b01-1cfe77ba48a1"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t sample_submission_stage_1.csv\ttest_stage_1.tsv\n",
            "gap-coreference  submission_1.csv\t\ttest_stage_1.tsv.zip\n",
            "sample_data\t submission_2.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nzK3Yj7YiVIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6d07e3c5-68da-40f4-9ef3-bd83a0b4ec6c"
      },
      "cell_type": "code",
      "source": [
        "!unzip test_stage_1.tsv.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test_stage_1.tsv.zip\n",
            "  inflating: test_stage_1.tsv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y84y7wFuicdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "6d9bfbcb-0959-4be7-f3db-270232337caf"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "!git clone https://github.com/google-research-datasets/gap-coreference.git\n",
        "\n",
        "#!wget 'https://github.com/google-research-datasets/gap-coreference/blob/master/gap-development.tsv'\n",
        "\n",
        "#!files.download('https://github.com/google-research-datasets/gap-coreference/blob/master/gap-development.tsv') # then browse, select the files. It's then uploaded\n",
        "\n",
        "# uploaded is now a dict containing \"filename\" -> Content"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gap-coreference'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Total 19 (delta 0), reused 0 (delta 0), pack-reused 19\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OSj7ykj9kmPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "789f76ea-09fc-424f-93f6-fe284e966618"
      },
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t sample_submission_stage_1.csv\ttest_stage_1.tsv\n",
            "gap-coreference  submission_1.csv\t\ttest_stage_1.tsv.zip\n",
            "sample_data\t submission_2.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RRXhMeXYlBFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### ======================== load test_stage_1\n",
        "with open('test_stage_1.tsv') as tsvfile:\n",
        "    reader = csv.DictReader(tsvfile, dialect='excel-tab')\n",
        "    testA_X = []\n",
        "    testB_X = []\n",
        "    test_auX = []\n",
        "    test_ids = []\n",
        "    train_auX = [] #we do a small hack and fill up the aux train data twice, like train hopping \n",
        "    for row in reader:\n",
        "        text = row['Text']\n",
        "        textA = text.lower()\n",
        "        test_auX.append(text.lower())#test aux is half size of train aux\n",
        "        train_auX.append(text.lower()) #since test loop is running, why not fill up aux train in meantime \n",
        "        new_textA = textA\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(textA)):\n",
        "            if char_idx == int(row['A-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"person_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"pronom_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "        testA_X.append(new_textA)\n",
        "        textB = text.lower()\n",
        "        new_textB = textB\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(textB)):\n",
        "            if char_idx == int(row['B-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"person_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"pronom_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "        testB_X.append(new_textB)\n",
        "        test_ids.append(row['ID'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_Ov5j4slsIg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b77f5734-5f7d-4f8b-ee31-6dd984b9dd12"
      },
      "cell_type": "code",
      "source": [
        "print(len(test_ids))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YaGUIpRsltZo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########=============================== Load gap-development.tsv ===================\n",
        "with open('/content/gap-coreference/gap-development.tsv') as tsvfile:\n",
        "    reader = csv.DictReader(tsvfile, dialect='excel-tab')\n",
        "#     print(*reader)\n",
        "    train_X = []\n",
        "    train_y = []\n",
        "    for row in reader:\n",
        "#         print(row)\n",
        "        text = row[\"Text\"]\n",
        "        text = text.lower()\n",
        "        train_auX.append(text)\n",
        "        new_textA = text\n",
        "        labelA = 0\n",
        "        labelB = 0\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(text)):\n",
        "            if char_idx == int(row['A-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"person_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textA = new_textA[:char_idx+check] + \"pronom_loc \" + new_textA[char_idx+check:]\n",
        "                check = 11\n",
        "        if row['A-coref'] == 'TRUE':\n",
        "            labelA = 1\n",
        "        train_X.append(new_textA)\n",
        "        train_y.append(labelA)\n",
        "        new_textB = text\n",
        "        label = 0\n",
        "        check = 0 #to allign the text in correct location after first insert\n",
        "        for char_idx in range(len(text)):\n",
        "            if char_idx == int(row['B-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"person_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "            if char_idx == int(row['Pronoun-offset']):\n",
        "                new_textB = new_textB[:char_idx+check] + \"pronom_loc \" + new_textB[char_idx+check:]\n",
        "                check = 11\n",
        "        if row['B-coref'] == 'TRUE':\n",
        "            labelB = 1\n",
        "        train_X.append(new_textB)\n",
        "        train_y.append(labelB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xzHyV88Wl58u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d7cc1c52-db0e-4e68-fdc4-59bcd5360602"
      },
      "cell_type": "code",
      "source": [
        "print(len(train_X))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vGjAFoiqpKM6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###============= Tokenize \n",
        "maxlen = 220\n",
        "embed_size = 500\n",
        "max_features = 7000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62w66gGmpPia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "123c4730-b336-4e35-92b3-ba14a1515d05"
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer_list = list(train_X)\n",
        "tokenizer.fit_on_texts(tokenizer_list)\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "testA_X = tokenizer.texts_to_sequences(testA_X)\n",
        "testB_X = tokenizer.texts_to_sequences(testB_X)\n",
        "test_auX = tokenizer.texts_to_sequences(test_auX)\n",
        "train_auX = tokenizer.texts_to_sequences(train_auX)\n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "testA_X = pad_sequences(testA_X, maxlen=maxlen)\n",
        "testB_X = pad_sequences(testB_X, maxlen=maxlen)\n",
        "test_auX = pad_sequences(test_auX, maxlen=maxlen)\n",
        "train_auX = pad_sequences(train_auX, maxlen=maxlen)\n",
        "\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "max_features = len(word_index)\n",
        "\n",
        "print(max_features)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mKyYwJgxpfHj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatible with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "      \n",
        "      \n",
        "class AttentionWithContext(Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number Îµ to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qZQOpj56prTL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_y = np.asarray(train_y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "142jGoYkpvny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##==========================Define CuDNNGRU model\n",
        "def get_model():\n",
        "  inp1 = Input(shape=(maxlen,))\n",
        "  inp2 = Input(shape=(maxlen,))\n",
        "\n",
        "  model1_out = Embedding(max_features, embed_size)(inp1)\n",
        "  model1_out = Bidirectional(CuDNNGRU(256, return_sequences=True))(model1_out)\n",
        "  model1_out = AttentionWithContext()(model1_out)\n",
        "  model1_out = Dropout(0.1)(model1_out)\n",
        "\n",
        "  model2_out = Embedding(max_features, embed_size)(inp2)\n",
        "  model2_out = Bidirectional(CuDNNGRU(256, return_sequences=True))(model2_out)\n",
        "  model2_out = AttentionWithContext()(model2_out)\n",
        "  model2_out = Dropout(0.1)(model2_out)\n",
        "\n",
        "  merged_out = keras.layers.Concatenate(axis=1)([model1_out, model2_out])\n",
        "\n",
        "  merged_out = Dense(32, activation=\"relu\")(merged_out)\n",
        "  merged_out = Dropout(0.1)(merged_out)\n",
        "  \n",
        "  merged_out = Dense(1, activation=\"sigmoid\")(merged_out)\n",
        "  model = Model(inputs=[inp1,inp2], outputs=merged_out)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e6a6eWRaBcoH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##==========================Define LSTM model\n",
        "def get_model_1():\n",
        "  inp1 = Input(shape=(maxlen,))\n",
        "  inp2 = Input(shape=(maxlen,))\n",
        "\n",
        "  model1_out = Embedding(max_features, embed_size)(inp1)\n",
        "  model1_out = Bidirectional(LSTM(256, return_sequences=True))(model1_out)\n",
        "  model1_out = AttentionWithContext()(model1_out)\n",
        "  model1_out = Dropout(0.1)(model1_out)\n",
        "\n",
        "  model2_out = Embedding(max_features, embed_size)(inp2)\n",
        "  model2_out = Bidirectional(LSTM(256, return_sequences=True))(model2_out)\n",
        "  model2_out = AttentionWithContext()(model2_out)\n",
        "  model2_out = Dropout(0.1)(model2_out)\n",
        "\n",
        "  merged_out = keras.layers.Concatenate(axis=1)([model1_out, model2_out])\n",
        "\n",
        "  merged_out = Dense(32, activation=\"relu\")(merged_out)\n",
        "  merged_out = Dropout(0.1)(merged_out)\n",
        "  \n",
        "  merged_out = Dense(1, activation=\"sigmoid\")(merged_out)\n",
        "  model = Model(inputs=[inp1,inp2], outputs=merged_out)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ifhlKUYBtmhB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model_gru():\n",
        "    inp = Input(shape=(maxlen, ))\n",
        "    x = Embedding(max_features, embed_size)(inp)\n",
        "    x = SpatialDropout1D(0.2)(x) # 0.2 -> 0.1\n",
        "    x = Bidirectional(GRU(80, return_sequences=True, activation='relu', dropout=0.1, recurrent_dropout=0.0))(x) # 80 -> 85\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
        "    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xfz7MVMytVwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "outputId": "8c4b05bd-5529-46b9-ce04-39b9e68da249"
      },
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "# model = get_model_gru()\n",
        "print(model.summary())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 220)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 220, 500)     11121500    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 220, 500)     11121500    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 220, 512)     1164288     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 220, 512)     1164288     embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_1 (Atten (None, 512)          263168      bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "attention_with_context_2 (Atten (None, 512)          263168      bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           attention_with_context_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512)          0           attention_with_context_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1024)         0           dropout_1[0][0]                  \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32)           32800       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            33          dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 25,130,745\n",
            "Trainable params: 25,130,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3vlc3awwp5vJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3727
        },
        "outputId": "3d940931-3301-48a6-ad57-1c881d9d61b9"
      },
      "cell_type": "code",
      "source": [
        "model.fit([train_X, train_auX], train_y, batch_size=512, epochs=100, validation_data=([train_X,train_auX], train_y))\n",
        "\n",
        "\n",
        "# model.fit(train_X, train_y, epochs=20, batch_size=32, validation_split=0.1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 4000 samples, validate on 4000 samples\n",
            "Epoch 1/100\n",
            "4000/4000 [==============================] - 17s 4ms/step - loss: 0.6897 - acc: 0.5485 - val_loss: 0.6880 - val_acc: 0.5503\n",
            "Epoch 2/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.6883 - acc: 0.5503 - val_loss: 0.6861 - val_acc: 0.5503\n",
            "Epoch 3/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.6852 - acc: 0.5503 - val_loss: 0.6770 - val_acc: 0.5503\n",
            "Epoch 4/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.6681 - acc: 0.5660 - val_loss: 0.6287 - val_acc: 0.7150\n",
            "Epoch 5/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.6419 - acc: 0.6390 - val_loss: 0.6126 - val_acc: 0.6967\n",
            "Epoch 6/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.5827 - acc: 0.7065 - val_loss: 0.5134 - val_acc: 0.7298\n",
            "Epoch 7/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.5378 - acc: 0.7033 - val_loss: 0.4691 - val_acc: 0.7470\n",
            "Epoch 8/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.4728 - acc: 0.7233 - val_loss: 0.4232 - val_acc: 0.7577\n",
            "Epoch 9/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.4160 - acc: 0.7505 - val_loss: 0.3445 - val_acc: 0.8312\n",
            "Epoch 10/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.3263 - acc: 0.8443 - val_loss: 0.2194 - val_acc: 0.9103\n",
            "Epoch 11/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.2117 - acc: 0.9147 - val_loss: 0.1242 - val_acc: 0.9550\n",
            "Epoch 12/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1201 - acc: 0.9553 - val_loss: 0.0622 - val_acc: 0.9803\n",
            "Epoch 13/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0601 - acc: 0.9788 - val_loss: 0.0351 - val_acc: 0.9888\n",
            "Epoch 14/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0372 - acc: 0.9888 - val_loss: 0.0240 - val_acc: 0.9940\n",
            "Epoch 15/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0235 - acc: 0.9942 - val_loss: 0.0120 - val_acc: 0.9985\n",
            "Epoch 16/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0129 - acc: 0.9970 - val_loss: 0.0072 - val_acc: 0.9985\n",
            "Epoch 17/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0028 - val_acc: 0.9995\n",
            "Epoch 18/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0030 - val_acc: 0.9998\n",
            "Epoch 19/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0068 - acc: 0.9990 - val_loss: 0.0023 - val_acc: 0.9995\n",
            "Epoch 20/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 9.0419e-04 - val_acc: 0.9998\n",
            "Epoch 21/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 4.4786e-04 - val_acc: 1.0000\n",
            "Epoch 22/100\n",
            "4000/4000 [==============================] - 14s 4ms/step - loss: 6.4044e-04 - acc: 1.0000 - val_loss: 5.6760e-04 - val_acc: 1.0000\n",
            "Epoch 23/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6041 - acc: 0.6060 - val_loss: 0.6924 - val_acc: 0.5503\n",
            "Epoch 24/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6922 - acc: 0.5502 - val_loss: 0.6920 - val_acc: 0.5503\n",
            "Epoch 25/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6919 - acc: 0.5503 - val_loss: 0.6917 - val_acc: 0.5503\n",
            "Epoch 26/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6915 - acc: 0.5502 - val_loss: 0.6913 - val_acc: 0.5503\n",
            "Epoch 27/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6911 - acc: 0.5503 - val_loss: 0.6909 - val_acc: 0.5503\n",
            "Epoch 28/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6908 - acc: 0.5503 - val_loss: 0.6906 - val_acc: 0.5503\n",
            "Epoch 29/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6905 - acc: 0.5503 - val_loss: 0.6904 - val_acc: 0.5503\n",
            "Epoch 30/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6903 - acc: 0.5503 - val_loss: 0.6901 - val_acc: 0.5503\n",
            "Epoch 31/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6900 - acc: 0.5502 - val_loss: 0.6899 - val_acc: 0.5503\n",
            "Epoch 32/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6898 - acc: 0.5503 - val_loss: 0.6897 - val_acc: 0.5503\n",
            "Epoch 33/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6896 - acc: 0.5503 - val_loss: 0.6895 - val_acc: 0.5503\n",
            "Epoch 34/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6894 - acc: 0.5502 - val_loss: 0.6894 - val_acc: 0.5503\n",
            "Epoch 35/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6893 - acc: 0.5503 - val_loss: 0.6892 - val_acc: 0.5503\n",
            "Epoch 36/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6892 - acc: 0.5502 - val_loss: 0.6891 - val_acc: 0.5503\n",
            "Epoch 37/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6891 - acc: 0.5502 - val_loss: 0.6890 - val_acc: 0.5503\n",
            "Epoch 38/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6890 - acc: 0.5502 - val_loss: 0.6889 - val_acc: 0.5503\n",
            "Epoch 39/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6889 - acc: 0.5503 - val_loss: 0.6888 - val_acc: 0.5503\n",
            "Epoch 40/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6888 - acc: 0.5502 - val_loss: 0.6887 - val_acc: 0.5503\n",
            "Epoch 41/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6887 - acc: 0.5503 - val_loss: 0.6887 - val_acc: 0.5503\n",
            "Epoch 42/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6886 - acc: 0.5503 - val_loss: 0.6886 - val_acc: 0.5503\n",
            "Epoch 43/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6886 - acc: 0.5503 - val_loss: 0.6885 - val_acc: 0.5503\n",
            "Epoch 44/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6885 - acc: 0.5503 - val_loss: 0.6885 - val_acc: 0.5503\n",
            "Epoch 45/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6885 - acc: 0.5503 - val_loss: 0.6884 - val_acc: 0.5503\n",
            "Epoch 46/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6884 - acc: 0.5503 - val_loss: 0.6884 - val_acc: 0.5503\n",
            "Epoch 47/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6884 - acc: 0.5503 - val_loss: 0.6884 - val_acc: 0.5503\n",
            "Epoch 48/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6883 - acc: 0.5503 - val_loss: 0.6883 - val_acc: 0.5503\n",
            "Epoch 49/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6883 - acc: 0.5502 - val_loss: 0.6883 - val_acc: 0.5503\n",
            "Epoch 50/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6883 - acc: 0.5503 - val_loss: 0.6883 - val_acc: 0.5503\n",
            "Epoch 51/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6883 - acc: 0.5502 - val_loss: 0.6882 - val_acc: 0.5503\n",
            "Epoch 52/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6882 - acc: 0.5503 - val_loss: 0.6882 - val_acc: 0.5503\n",
            "Epoch 53/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6882 - acc: 0.5502 - val_loss: 0.6882 - val_acc: 0.5503\n",
            "Epoch 54/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6882 - acc: 0.5502 - val_loss: 0.6882 - val_acc: 0.5503\n",
            "Epoch 55/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6882 - acc: 0.5503 - val_loss: 0.6882 - val_acc: 0.5503\n",
            "Epoch 56/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6882 - acc: 0.5502 - val_loss: 0.6882 - val_acc: 0.5503\n",
            "Epoch 57/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6882 - acc: 0.5502 - val_loss: 0.6882 - val_acc: 0.5503\n",
            "Epoch 58/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6882 - acc: 0.5502 - val_loss: 0.6882 - val_acc: 0.5503\n",
            "Epoch 59/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 60/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 61/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 62/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 63/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 64/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 65/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 66/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 67/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 68/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 69/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 70/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 71/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 72/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 73/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 74/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 75/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 76/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 77/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 78/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 79/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 80/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 81/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 82/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 83/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 84/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 85/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 86/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 87/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 88/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 89/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 90/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 91/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 92/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 93/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 94/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 95/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 96/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 97/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 98/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 99/100\n",
            "4000/4000 [==============================] - 13s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n",
            "Epoch 100/100\n",
            "4000/4000 [==============================] - 14s 3ms/step - loss: 0.6881 - acc: 0.5503 - val_loss: 0.6881 - val_acc: 0.5503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9605cfd6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "MjZt9hhYp_h7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "05ac9948-762d-4ec9-e1d7-2563745a970b"
      },
      "cell_type": "code",
      "source": [
        "pred_valA_y = model.predict([testA_X,test_auX], batch_size=512, verbose=1)\n",
        "pred_valB_y = model.predict([testB_X,test_auX], batch_size=512, verbose=1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 2s 917us/step\n",
            "2000/2000 [==============================] - 2s 826us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yZXHWKjvxNzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "924b014b-786f-4596-8a5e-6bab3804a812"
      },
      "cell_type": "code",
      "source": [
        "print(len(pred_valB_y), \" \", len(pred_valA_y))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000   2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i0dfiT8nxRO5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df = pd.DataFrame({\"ID\":test_ids})\n",
        "out_df['A'] = [max(float(val),0.33) for val in list(pred_valA_y)]\n",
        "out_df['B'] = [max(float(val),0.33) for val in list(pred_valB_y)]\n",
        "out_df['NEITHER'] = [max((1-float(val)),0.33) for val in list(pred_valA_y)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gVJuG_wZT7JT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "b6d0b022-b764-4f8b-d12e-d97aababacc9"
      },
      "cell_type": "code",
      "source": [
        "out_df.head(10)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>NEITHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>development-6</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>development-7</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>development-8</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development-9</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>development-10</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID         A         B   NEITHER\n",
              "0   development-1  0.449853  0.449853  0.550147\n",
              "1   development-2  0.449853  0.449853  0.550147\n",
              "2   development-3  0.449853  0.449853  0.550147\n",
              "3   development-4  0.449853  0.449853  0.550147\n",
              "4   development-5  0.449853  0.449853  0.550147\n",
              "5   development-6  0.449853  0.449853  0.550147\n",
              "6   development-7  0.449853  0.449853  0.550147\n",
              "7   development-8  0.449853  0.449853  0.550147\n",
              "8   development-9  0.449853  0.449853  0.550147\n",
              "9  development-10  0.449853  0.449853  0.550147"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "rgrDTAZkUh3c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "subm_1 = pd.read_csv('/content/submission_1.csv')\n",
        "subm_2 = pd.read_csv('/content/submission_2.csv')\n",
        "subm_3 = pd.read_csv('/content/submission_3.csv')\n",
        "subm_4 = pd.read_csv('/content/submission_4.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GyDJe7fQVv93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "25a5ed1c-574a-4c96-ec79-d655960d4383"
      },
      "cell_type": "code",
      "source": [
        "subm_1.head(10)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>NEITHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>0.988302</td>\n",
              "      <td>0.999060</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.999436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>0.663525</td>\n",
              "      <td>0.999387</td>\n",
              "      <td>0.336475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.583480</td>\n",
              "      <td>0.999978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>development-6</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999806</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>development-7</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.966465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>development-8</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.796346</td>\n",
              "      <td>0.999729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development-9</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.997234</td>\n",
              "      <td>0.998847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>development-10</td>\n",
              "      <td>0.989855</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID         A         B   NEITHER\n",
              "0   development-1  0.988302  0.999060  0.330000\n",
              "1   development-2  0.330000  0.330000  0.999436\n",
              "2   development-3  0.663525  0.999387  0.336475\n",
              "3   development-4  0.330000  0.583480  0.999978\n",
              "4   development-5  0.330000  0.330000  0.999999\n",
              "5   development-6  0.999999  0.999806  0.330000\n",
              "6   development-7  0.330000  0.330000  0.966465\n",
              "7   development-8  0.330000  0.796346  0.999729\n",
              "8   development-9  0.330000  0.997234  0.998847\n",
              "9  development-10  0.989855  0.330000  0.330000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "aBJf6vGJVwoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "c4d959e9-4860-4c54-cc2d-0674e632960b"
      },
      "cell_type": "code",
      "source": [
        "subm_2.head(10)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>NEITHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>0.999787</td>\n",
              "      <td>0.999783</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.999556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>0.995672</td>\n",
              "      <td>0.995730</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>0.641542</td>\n",
              "      <td>0.641542</td>\n",
              "      <td>0.358458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>0.641542</td>\n",
              "      <td>0.641542</td>\n",
              "      <td>0.358458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>development-6</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.998124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>development-7</td>\n",
              "      <td>0.999808</td>\n",
              "      <td>0.999792</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>development-8</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.970400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development-9</td>\n",
              "      <td>0.966441</td>\n",
              "      <td>0.997570</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>development-10</td>\n",
              "      <td>0.641542</td>\n",
              "      <td>0.641542</td>\n",
              "      <td>0.358458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID         A         B   NEITHER\n",
              "0   development-1  0.999787  0.999783  0.330000\n",
              "1   development-2  0.330000  0.330000  0.999556\n",
              "2   development-3  0.995672  0.995730  0.330000\n",
              "3   development-4  0.641542  0.641542  0.358458\n",
              "4   development-5  0.641542  0.641542  0.358458\n",
              "5   development-6  0.330000  0.330000  0.998124\n",
              "6   development-7  0.999808  0.999792  0.330000\n",
              "7   development-8  0.330000  0.330000  0.970400\n",
              "8   development-9  0.966441  0.997570  0.330000\n",
              "9  development-10  0.641542  0.641542  0.358458"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "fcGCZa6yWQJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "996baa96-138f-47e8-f75a-0de9c81745cf"
      },
      "cell_type": "code",
      "source": [
        "subm_3.head(10)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>NEITHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>development-6</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>development-7</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>development-8</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development-9</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>development-10</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.550147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID         A         B   NEITHER\n",
              "0   development-1  0.449853  0.449853  0.550147\n",
              "1   development-2  0.449853  0.449853  0.550147\n",
              "2   development-3  0.449853  0.449853  0.550147\n",
              "3   development-4  0.449853  0.449853  0.550147\n",
              "4   development-5  0.449853  0.449853  0.550147\n",
              "5   development-6  0.449853  0.449853  0.550147\n",
              "6   development-7  0.449853  0.449853  0.550147\n",
              "7   development-8  0.449853  0.449853  0.550147\n",
              "8   development-9  0.449853  0.449853  0.550147\n",
              "9  development-10  0.449853  0.449853  0.550147"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "8DIVTn9DYxAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "97a411de-3f5e-48e5-b745-fd88d6e10276"
      },
      "cell_type": "code",
      "source": [
        "subm_4.head(10)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>NEITHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>development-6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>development-7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>development-8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development-9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>development-10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID    A    B  NEITHER\n",
              "0   development-1  1.0  1.0      1.0\n",
              "1   development-2  1.0  1.0      1.0\n",
              "2   development-3  1.0  1.0      1.0\n",
              "3   development-4  1.0  1.0      1.0\n",
              "4   development-5  1.0  1.0      1.0\n",
              "5   development-6  1.0  1.0      1.0\n",
              "6   development-7  1.0  1.0      1.0\n",
              "7   development-8  1.0  1.0      1.0\n",
              "8   development-9  1.0  1.0      1.0\n",
              "9  development-10  1.0  1.0      1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "Nfcbx-LWcDMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "answers = pd.read_csv('/content/submission_1.csv', dtype={'A-coref': int, 'B-coref': int})\n",
        "answers.rename(columns={'A-coref': 'A', 'B-coref': 'B'}, inplace=True)\n",
        "answers['NEITHER'] = answers.eval('1 - A - B')\n",
        "answers[['ID', 'A', 'B', 'NEITHER']].to_csv(\"answers.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "isE51rP7dXrB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answers[['ID', 'A', 'B', 'NEITHER']].to_csv(\"/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /answers.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1pnZlkTcgZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "09fbcd6e-876f-46be-ad55-7bb4c742556e"
      },
      "cell_type": "code",
      "source": [
        "answers.head(10)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>NEITHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>0.988302</td>\n",
              "      <td>0.999060</td>\n",
              "      <td>-0.987362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>0.663525</td>\n",
              "      <td>0.999387</td>\n",
              "      <td>-0.662912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.583480</td>\n",
              "      <td>0.086520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>development-6</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.999806</td>\n",
              "      <td>-0.999805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>development-7</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>development-8</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.796346</td>\n",
              "      <td>-0.126346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development-9</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.997234</td>\n",
              "      <td>-0.327234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>development-10</td>\n",
              "      <td>0.989855</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>-0.319855</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID         A         B   NEITHER\n",
              "0   development-1  0.988302  0.999060 -0.987362\n",
              "1   development-2  0.330000  0.330000  0.340000\n",
              "2   development-3  0.663525  0.999387 -0.662912\n",
              "3   development-4  0.330000  0.583480  0.086520\n",
              "4   development-5  0.330000  0.330000  0.340000\n",
              "5   development-6  0.999999  0.999806 -0.999805\n",
              "6   development-7  0.330000  0.330000  0.340000\n",
              "7   development-8  0.330000  0.796346 -0.126346\n",
              "8   development-9  0.330000  0.997234 -0.327234\n",
              "9  development-10  0.989855  0.330000 -0.319855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "ROd6JbFIZJHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "911cb50b-985b-4f02-f5d3-ffe9bf43f655"
      },
      "cell_type": "code",
      "source": [
        "print(max(subm_1['A']), max(subm_2['A']), max(subm_3['A']))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0 0.9999995827674866 0.4498527944087982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oq-dHBzbZPtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09d9009d-bb43-4be2-f9f3-fb1820eea46b"
      },
      "cell_type": "code",
      "source": [
        "print(max(subm_1['B']), max(subm_2['B']), max(subm_3['B']))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0 0.9999995231628418 0.4498527944087982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SNCfngnMZQOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "08b75bff-8544-49ff-c8ea-7b105d83b90e"
      },
      "cell_type": "code",
      "source": [
        "print(max(subm_1['NEITHER']), max(subm_2['NEITHER']), max(subm_3['NEITHER']))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9999999701976776 1.0 0.5501472055912018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TxfDlK4xWd-G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df['A'] = max(max(subm_2['A']), max(subm_3['A']))\n",
        "out_df['B'] = max(max(subm_2['B']), max(subm_3['B']))\n",
        "out_df['NEITHER'] = max(max(subm_1['NEITHER']), max(subm_3['NEITHER']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-bwRBhWkxZ-i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df.to_csv(\"submission_5.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uYrFmuMbxenQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "27c069ea-9d2a-4fff-a008-aecf8221ae12"
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution '"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " gendered-pronoun-resolution\n",
            "'Gendered Pronoun Resolution: Version-04.ipynb'\n",
            " submission_1.csv\n",
            " submission_2.csv\n",
            " submission_3.csv\n",
            " submission_4.csv\n",
            "'Top 3 NLP Libraries Tutorial( NLTK+spaCy+Gensim).ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DruSyLnUxov-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_df.to_csv(\"/content/drive/My Drive/Kaggle Competition: Gendered Pronoun Resolution /submission_5.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuEZiS8Ax62F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "8f26128c-6893-476e-d778-cf8b4410c07c"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c gendered-pronoun-resolution -f answers.csv -m \"V-06\""
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "100% 116k/116k [00:03<00:00, 38.7kB/s]\n",
            "Successfully submitted to Gendered Pronoun Resolution"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "77C2wmuuyI-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}